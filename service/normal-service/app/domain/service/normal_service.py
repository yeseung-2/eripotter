"""
Normal Service - ìƒˆë¡œìš´ í…Œì´ë¸” êµ¬ì¡°ì— ë§ì¶˜ í†µí•© ì„œë¹„ìŠ¤
í”„ë¡ íŠ¸ì—”ë“œ ë°ì´í„° ì²˜ë¦¬ + AI ë§¤í•‘ + ì‚¬ìš©ì ê²€í† 
"""
from eripotter_common.database.base import get_db_engine
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
import pandas as pd
import numpy as np
import faiss
import os
from pathlib import Path
from sentence_transformers import SentenceTransformer
# SubstanceMappingRepositoryëŠ” ì´ì œ NormalRepositoryì— í†µí•©ë¨
from ..repository.normal_repository import NormalRepository
from .data_normalization_service import DataNormalizationService

from .interfaces import ISubstanceMapping, IDataNormalization, IESGValidation

logger = logging.getLogger("normal-service")

class NormalService(ISubstanceMapping, IDataNormalization, IESGValidation):
    """í†µí•© Normal ì„œë¹„ìŠ¤ - ìƒˆë¡œìš´ í…Œì´ë¸” êµ¬ì¡° ëŒ€ì‘"""
    
    def __init__(self):
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ ì„ íƒì ìœ¼ë¡œ ì‹œë„
        self.engine = None
        self.normal_repository = None
        self.db_available = False
        
        try:
            self.engine = get_db_engine()
            self.normal_repository = NormalRepository()
            self.db_available = True
            logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
        except Exception as e:
            logger.warning(f"âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            logger.info("ğŸ“ AI ë§¤í•‘ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤ (ê²°ê³¼ ì €ì¥ ë¶ˆê°€)")
        
        # ê¸°ëŠ¥ë³„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.data_normalization_service = DataNormalizationService()
        
        # Substance Mapping ê´€ë ¨ ì´ˆê¸°í™”
        self.model = None
        self.regulation_data = None
        self.faiss_index = None
        self.regulation_sids = None
        self.regulation_names = None
        self._load_model_and_data()

    # ===== í”„ë¡ íŠ¸ì—”ë“œ ë°ì´í„° ì²˜ë¦¬ ë©”ì„œë“œë“¤ =====
    
    def save_substance_data_only(self, substance_data: Dict[str, Any], company_id: str = None, company_name: str = None, uploaded_by: str = None) -> Dict[str, Any]:
        """í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë°›ì€ ë¬¼ì§ˆ ë°ì´í„°ë§Œ ì €ì¥ (AI ë§¤í•‘ì€ ë³„ë„)"""
        try:
            logger.info(f"ğŸ“ ë¬¼ì§ˆ ë°ì´í„° ì €ì¥ ì‹œì‘: {substance_data.get('productName', 'Unknown')}")
            
            if not self.db_available:
                return {
                    "status": "error",
                    "message": "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤."
                }
            
            # Normal í…Œì´ë¸”ì— ë°ì´í„° ì €ì¥
            normal_id = self.normal_repository.save_substance_data(
                substance_data=substance_data,
                company_id=company_id,
                company_name=company_name,
                uploaded_by=uploaded_by,
                uploaded_by_email=substance_data.get('uploadedByEmail')
            )
            
            if not normal_id:
                return {
                    "status": "error",
                    "message": "ë¬¼ì§ˆ ë°ì´í„° ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                }
            
            logger.info(f"âœ… ë¬¼ì§ˆ ë°ì´í„° ì €ì¥ ì™„ë£Œ: Normal ID {normal_id}")
            
            return {
                "status": "success",
                "normal_id": normal_id,
                "product_name": substance_data.get('productName'),
                "message": "ë¬¼ì§ˆ ë°ì´í„° ì €ì¥ ì™„ë£Œ. ìë™ë§¤í•‘ì„ ì‹œì‘í•˜ì„¸ìš”."
            }
            
        except Exception as e:
            logger.error(f"âŒ ë¬¼ì§ˆ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "error": str(e),
                "message": "ë¬¼ì§ˆ ë°ì´í„° ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }

    def start_auto_mapping(self, normal_id: int, company_id: str = None, company_name: str = None) -> Dict[str, Any]:
        """ìë™ë§¤í•‘ ì‹œì‘ - ì €ì¥ëœ ë°ì´í„°ì˜ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ì„ AIë¡œ ë§¤í•‘"""
        try:
            logger.info(f"ğŸ¤– ìë™ë§¤í•‘ ì‹œì‘: Normal ID {normal_id}")
            
            if not self.db_available:
                return {
                    "status": "error",
                    "message": "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤."
                }
            
            # Normal í…Œì´ë¸”ì—ì„œ ë°ì´í„° ì¡°íšŒ
            normal_data = self.normal_repository.get_by_id(normal_id)
            if not normal_data:
                return {
                    "status": "error",
                    "message": f"Normal ID {normal_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                }
            
            # ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ ë°ì´í„° ì¶”ì¶œ
            greenhouse_gases = normal_data.greenhouse_gas_emissions or []
            if not greenhouse_gases:
                return {
                    "status": "error",
                    "message": "ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
                }
            
            mapping_results = []
            certification_ids = []
            
            logger.info(f"ğŸ¤– ì˜¨ì‹¤ê°€ìŠ¤ AI ë§¤í•‘ ì‹œì‘: {len(greenhouse_gases)}ê°œ")
            
            for gas_data in greenhouse_gases:
                gas_name = gas_data.get('materialName', '')
                gas_amount = gas_data.get('amount', '')
                
                if gas_name:
                    # AI ë§¤í•‘ ìˆ˜í–‰
                    ai_result = self.map_substance(gas_name)
                    
                    # Certification í…Œì´ë¸”ì— ì €ì¥
                    if ai_result.get('status') == 'success':
                        success = self.normal_repository.save_ai_mapping_result(
                            normal_id=normal_id,
                            gas_name=gas_name,
                            gas_amount=gas_amount,
                            mapping_result=ai_result,
                            company_id=company_id,
                            company_name=company_name
                        )
                        
                        if success:
                            # ì‹ ë¢°ë„ì— ë”°ë¥¸ ìƒíƒœ ê²°ì •
                            confidence = ai_result.get('confidence', 0.0)
                            if confidence >= 0.7:
                                status = 'auto_mapped'
                            elif confidence >= 0.4:
                                status = 'needs_review'
                            else:
                                status = 'needs_review'  # ë‚®ì€ ì‹ ë¢°ë„ë„ ê²€í†  í•„ìš”
                            
                            mapping_results.append({
                                'original_gas_name': gas_name,
                                'original_amount': gas_amount,
                                'ai_mapped_name': ai_result.get('mapped_name'),
                                'ai_confidence': ai_result.get('confidence'),
                                'status': status,
                                'certification_id': None  # ë‚˜ì¤‘ì— ì¡°íšŒí•´ì„œ ì±„ì›Œë„£ê¸°
                            })
                        else:
                            mapping_results.append({
                                'original_gas_name': gas_name,
                                'status': 'save_failed'
                            })
                    else:
                        mapping_results.append({
                            'original_gas_name': gas_name,
                            'status': 'mapping_failed',
                            'error': ai_result.get('error')
                        })
            
            # ìƒì„±ëœ certification IDë“¤ ì¡°íšŒ
            saved_mappings = self.normal_repository.get_saved_mappings(company_id, limit=len(mapping_results))
            for i, mapping in enumerate(mapping_results):
                if i < len(saved_mappings):
                    mapping['certification_id'] = saved_mappings[i]['id']
            
            logger.info(f"âœ… ìë™ë§¤í•‘ ì™„ë£Œ: {len(mapping_results)}ê°œ ë§¤í•‘")
            
            return {
                "status": "success",
                "normal_id": normal_id,
                "mapping_results": mapping_results,
                "message": f"ìë™ë§¤í•‘ ì™„ë£Œ: {len(mapping_results)}ê°œ ì˜¨ì‹¤ê°€ìŠ¤ ë§¤í•‘. ì‚¬ìš©ì ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            }
            
        except Exception as e:
            logger.error(f"âŒ ìë™ë§¤í•‘ ì‹¤íŒ¨: {e}")
            return {
                "status": "error",
                "error": str(e),
                "message": "ìë™ë§¤í•‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            }

    def get_substance_mapping_statistics(self) -> Dict[str, Any]:
        """ë¬¼ì§ˆ ë§¤í•‘ í†µê³„ ì¡°íšŒ (ìƒˆë¡œìš´ êµ¬ì¡°)"""
        try:
            if not self.db_available:
                return {"error": "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¶ˆê°€"}
            
            # Repositoryì—ì„œ í†µê³„ ì¡°íšŒ
            stats = self.normal_repository.get_mapping_statistics()
            
            # AI ì„œë¹„ìŠ¤ í†µê³„ ì¶”ê°€
            ai_stats = self.get_substance_mapping_statistics()
            
            return {
                "database_stats": stats,
                "ai_model_stats": ai_stats,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ ë§¤í•‘ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    def get_saved_mappings(self, company_id: str = None, limit: int = 10) -> List[Dict[str, Any]]:
        """ì €ì¥ëœ ë§¤í•‘ ê²°ê³¼ ì¡°íšŒ"""
        if not self.db_available:
            return []
        
        return self.normal_repository.get_saved_mappings(company_id, limit)

    def get_original_data(self, company_id: str = None, limit: int = 10) -> List[Dict[str, Any]]:
        """ì›ë³¸ ë°ì´í„° ì¡°íšŒ"""
        if not self.db_available:
            return []
        
        return self.normal_repository.get_original_data(company_id, limit)

    def get_corrections(self, company_id: str = None, limit: int = 10) -> List[Dict[str, Any]]:
        """ì‚¬ìš©ì ìˆ˜ì • ë°ì´í„° ì¡°íšŒ"""
        # í˜„ì¬ëŠ” certification í…Œì´ë¸”ì—ì„œ user_reviewed ìƒíƒœì¸ ê²ƒë“¤ ì¡°íšŒ
        try:
            if not self.db_available:
                return []
            
            # TODO: Repositoryì— ë©”ì„œë“œ ì¶”ê°€ í•„ìš”
            return []
            
        except Exception as e:
            logger.error(f"âŒ ìˆ˜ì • ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def correct_mapping(self, certification_id: int, correction_data: Dict[str, Any]) -> bool:
        """ë§¤í•‘ ê²°ê³¼ ìˆ˜ë™ ìˆ˜ì •"""
        if not self.db_available:
            return False
        
        return self.normal_repository.update_user_mapping_correction(
            certification_id=certification_id,
            correction_data=correction_data,
            reviewed_by=correction_data.get('reviewed_by', 'user')
        )

    def save_mapping_correction(self, **kwargs):
        """ë§¤í•‘ ìˆ˜ì • ê²°ê³¼ ì €ì¥ (ë ˆê±°ì‹œ í˜¸í™˜)"""
        # ìƒˆë¡œìš´ êµ¬ì¡°ì—ì„œëŠ” correct_mapping ì‚¬ìš©
        return True

    # ===== ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ê°œì„ ) =====
    
    def upload_and_normalize_excel(self, file):
        """ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ ë° ì •ê·œí™” (ìƒˆë¡œìš´ êµ¬ì¡° ëŒ€ì‘)"""
        try:
            logger.info(f"ğŸ“ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ: {file.filename}")
            
            # íŒŒì¼ ë‚´ìš© ì½ê¸°
            content = file.file.read()
            
            # 1ë‹¨ê³„: ë°ì´í„° ì •ê·œí™”
            normalization_result = self.data_normalization_service.normalize_excel_data(
                file_data=content,
                filename=file.filename
            )
            
            if normalization_result['status'] == 'error':
                return normalization_result
            
            # 2ë‹¨ê³„: ì •ê·œí™”ëœ ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ êµ¬ì¡°ë¡œ ë³€í™˜
            normalized_data = normalization_result.get('normalized_data', [])
            converted_results = []
            
            for item in normalized_data:
                # ì—‘ì…€ ë°ì´í„°ë¥¼ í”„ë¡ íŠ¸ì—”ë“œ êµ¬ì¡°ë¡œ ë³€í™˜
                substance_data = {
                    'filename': file.filename,
                    'file_size': len(content),
                    'file_type': 'excel',
                    'productName': item.get('substance_name', ''),
                    'greenhouseGasEmissions': [
                        {
                            'materialName': item.get('substance_name', ''),
                            'amount': str(item.get('amount', 0)),
                            'unit': item.get('unit', 'tonCO2eq')
                        }
                    ]
                }
                
                # ë°ì´í„° ì €ì¥ ë° ë§¤í•‘
                result = self.save_substance_data_and_map_gases(
                    substance_data=substance_data,
                    company_id=item.get('company_id'),
                    company_name=item.get('company_name'),
                    uploaded_by=item.get('uploaded_by')
                )
                
                converted_results.append(result)
            
            return {
                "filename": file.filename,
                "status": "uploaded_and_mapped",
                "normalization": normalization_result,
                "conversion_results": converted_results,
                "message": f"ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {len(converted_results)}ê°œ í•­ëª©"
            }
            
        except Exception as e:
            logger.error(f"âŒ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ ë° ë§¤í•‘ ì‹¤íŒ¨: {e}")
            return {
                "filename": file.filename,
                "status": "error",
                "error": str(e)
            }

    # ===== ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ í˜¸í™˜ì„± ë©”ì„œë“œë“¤ =====
    
    def map_substance(self, substance_name: str, company_id: str = None) -> dict:
        """ë‹¨ì¼ ë¬¼ì§ˆ ë§¤í•‘ (AIë§Œ)"""
        try:
            logger.info(f"ğŸ“ ë¬¼ì§ˆ ë§¤í•‘ ìš”ì²­: {substance_name}")
            
            if not substance_name or substance_name.strip() == "":
                return self._create_empty_result(substance_name, "ë¹ˆ ë¬¼ì§ˆëª…")
            
            # ê·œì • ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ì‘ë‹µ
            if not self.regulation_sids or not self.regulation_names:
                return {
                    "substance_name": substance_name,
                    "mapped_sid": None,
                    "mapped_name": None,
                    "top1_score": 0.0,
                    "margin": 0.0,
                    "confidence": 0.0,
                    "band": "not_mapped",
                    "top5_candidates": [],
                    "message": "ê·œì • ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                    "status": "no_data"
                }
            
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_text = f"query: {substance_name.strip()}"
            query_embedding = self.model.encode(
                [query_text], 
                normalize_embeddings=True,
                show_progress_bar=False
            ).astype("float32")
            
            # FAISS ê²€ìƒ‰
            scores, indices = self.faiss_index.search(query_embedding, 5)
            
            # ê²°ê³¼ ì²˜ë¦¬
            top1_score = float(scores[0][0])
            top2_score = float(scores[0][1]) if len(scores[0]) > 1 else 0.0
            margin = max(top1_score - top2_score, 0.0)
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = 0.85 * top1_score + 0.15 * margin
            
            # ì‹ ë¢°ë„ ë°´ë“œ ê²°ì •
            if confidence >= 0.70:
                band = "mapped"
            elif confidence >= 0.40:
                band = "needs_review"
            else:
                band = "not_mapped"
            
            # Top-5 í›„ë³´ë“¤
            top5_candidates = []
            for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
                if idx < len(self.regulation_sids):
                    top5_candidates.append({
                        "rank": i + 1,
                        "sid": self.regulation_sids[idx],
                        "name": self.regulation_names[idx],
                        "score": float(score)
                    })
            
            result = {
                "substance_name": substance_name,
                "mapped_sid": self.regulation_sids[indices[0][0]] if indices[0][0] < len(self.regulation_sids) else None,
                "mapped_name": self.regulation_names[indices[0][0]] if indices[0][0] < len(self.regulation_names) else None,
                "top1_score": top1_score,
                "margin": margin,
                "confidence": confidence,
                "band": band,
                "top5_candidates": top5_candidates,
                "status": "success"
            }
            
            logger.info(f"âœ… ë¬¼ì§ˆ ë§¤í•‘ ì™„ë£Œ: {substance_name} -> {result.get('mapped_name', 'None')}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ë¬¼ì§ˆ ë§¤í•‘ ì‹¤íŒ¨: {e}")
            return self._create_empty_result(substance_name, str(e))
    
    def map_substances_batch(self, substance_names: list, company_id: str = None) -> list:
        """ë°°ì¹˜ ë¬¼ì§ˆ ë§¤í•‘ (AIë§Œ)"""
        try:
            if not substance_names:
                raise Exception("ë§¤í•‘í•  ë¬¼ì§ˆëª… ëª©ë¡ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            
            logger.info(f"ğŸ“ ë°°ì¹˜ ë¬¼ì§ˆ ë§¤í•‘ ìš”ì²­: {len(substance_names)}ê°œ")
            
            results = []
            for substance_name in substance_names:
                result = self.map_substance(substance_name, company_id)
                results.append(result)
            
            logger.info(f"âœ… ë°°ì¹˜ ë¬¼ì§ˆ ë§¤í•‘ ì™„ë£Œ: {len(results)}ê°œ")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ë¬¼ì§ˆ ë§¤í•‘ ì‹¤íŒ¨: {e}")
            raise Exception(f"ë°°ì¹˜ ë¬¼ì§ˆ ë§¤í•‘ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
    
    def map_file(self, file_path: str) -> dict:
        """íŒŒì¼ì—ì„œ ë¬¼ì§ˆëª…ì„ ì¶”ì¶œí•˜ì—¬ ë§¤í•‘í•©ë‹ˆë‹¤."""
        try:
            # íŒŒì¼ ì½ê¸°
            if file_path.endswith('.xlsx') or file_path.endswith('.xls'):
                data = pd.read_excel(file_path)
            elif file_path.endswith('.csv'):
                data = pd.read_csv(file_path)
            else:
                raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
            
            # ë¬¼ì§ˆëª… ì»¬ëŸ¼ ì°¾ê¸° (ì»¬ëŸ¼ëª…ì— 'ë¬¼ì§ˆ', 'substance', 'name' ë“±ì´ í¬í•¨ëœ ê²ƒ)
            substance_column = None
            for col in data.columns:
                col_lower = str(col).lower()
                if any(keyword in col_lower for keyword in ['ë¬¼ì§ˆ', 'substance', 'name', 'chemical']):
                    substance_column = col
                    break
            
            if substance_column is None:
                # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì„ ë¬¼ì§ˆëª…ìœ¼ë¡œ ê°€ì •
                substance_column = data.columns[0]
            
            # ë¬¼ì§ˆëª… ì¶”ì¶œ
            substance_names = data[substance_column].fillna("").astype(str).tolist()
            
            # ë§¤í•‘ ìˆ˜í–‰
            mapping_results = self.map_substances_batch(substance_names)
            
            # í†µê³„ ê³„ì‚°
            total_count = len(mapping_results)
            mapped_count = sum(1 for r in mapping_results if r['band'] == 'mapped')
            review_count = sum(1 for r in mapping_results if r['band'] == 'needs_review')
            not_mapped_count = sum(1 for r in mapping_results if r['band'] == 'not_mapped')
            
            return {
                "file_path": file_path,
                "total_substances": total_count,
                "mapped_count": mapped_count,
                "needs_review_count": review_count,
                "not_mapped_count": not_mapped_count,
                "mapping_results": mapping_results,
                "status": "success"
            }
            
        except Exception as e:
            logger.error(f"íŒŒì¼ ë§¤í•‘ ì‹¤íŒ¨ ({file_path}): {e}")
            return {
                "file_path": file_path,
                "error": str(e),
                "status": "error"
            }

    # ===== ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„ (ì¶”ìƒ ë©”ì„œë“œë“¤) =====
    
    def get_mapping_statistics(self) -> dict:
        """ë§¤í•‘ í†µê³„ ì¡°íšŒ (ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„)"""
        return self.get_substance_mapping_statistics()
    
    def normalize_excel_data(self, file_data: bytes, filename: str, company_id: str = None) -> dict:
        """ì—‘ì…€ ë°ì´í„° ì •ê·œí™” (ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„)"""
        return self.data_normalization_service.normalize_excel_data(file_data, filename)
    
    def validate_data_structure(self, data: dict) -> dict:
        """ë°ì´í„° êµ¬ì¡° ê²€ì¦ (ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„)"""
        return {"status": "valid", "data": data}
    
    def standardize_data(self, data: dict) -> dict:
        """ë°ì´í„° í‘œì¤€í™” (ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„)"""
        return data
    
    def validate_esg_data(self, data: dict, industry: str = None) -> dict:
        """ESG ë°ì´í„° ê²€ì¦ (ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„)"""
        return {"status": "valid", "data": data}
    
    def calculate_esg_score(self, data: dict) -> int:
        """ESG ì ìˆ˜ ê³„ì‚° (ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„)"""
        return 85  # ê¸°ë³¸ ì ìˆ˜
    
    def generate_esg_report(self, company_id: str, report_type: str) -> dict:
        """ESG ë³´ê³ ì„œ ìƒì„± (ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„)"""
        return {"company_id": company_id, "report_type": report_type, "status": "generated"}

    # ===== ë ˆê±°ì‹œ ë©”ì„œë“œë“¤ (í˜¸í™˜ì„±) =====
    
    def get_all_normalized_data(self):
        """ëª¨ë“  ì •ê·œí™” ë°ì´í„° ì¡°íšŒ"""
        return self.get_original_data(limit=50)

    def get_normalized_data_by_id(self, data_id: str):
        """íŠ¹ì • ì •ê·œí™” ë°ì´í„° ì¡°íšŒ"""
        if not self.db_available:
            return {"id": data_id, "error": "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¶ˆê°€"}
        
        try:
            normal_entity = self.normal_repository.get_by_id(int(data_id))
            return normal_entity.to_dict() if normal_entity else {"error": "ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        except:
            return {"id": data_id, "error": "ì¡°íšŒ ì‹¤íŒ¨"}

    def create_normalized_data(self, data: dict):
        """ì •ê·œí™” ë°ì´í„° ìƒì„±"""
        return data

    def update_normalized_data(self, data_id: str, data: dict):
        """ì •ê·œí™” ë°ì´í„° ì—…ë°ì´íŠ¸"""
        return {"id": data_id, **data}

    def delete_normalized_data(self, data_id: str):
        """ì •ê·œí™” ë°ì´í„° ì‚­ì œ"""
        return True

    def get_metrics(self):
        """ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        return self.get_substance_mapping_statistics()

    # ===== í˜‘ë ¥ì‚¬ ESG ê´€ë ¨ ë©”ì„œë“œë“¤ (ê¸°ì¡´ ìœ ì§€) =====
    
    def upload_partner_esg_data(self, file, company_id: str = None):
        """í˜‘ë ¥ì‚¬ ESG ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ"""
        return {"status": "not_implemented"}

    def validate_partner_esg_data(self, data: dict):
        """í˜‘ë ¥ì‚¬ ESG ë°ì´í„° ê²€ì¦"""
        return {"status": "not_implemented"}

    def get_partner_dashboard(self, company_id: str):
        """í˜‘ë ¥ì‚¬ ìê°€ì§„ë‹¨ ëŒ€ì‹œë³´ë“œ"""
        return {"company_id": company_id, "status": "not_implemented"}

    def generate_partner_report(self, report_type: str, company_id: str):
        """í˜‘ë ¥ì‚¬ ESG ë³´ê³ ì„œ ìƒì„±"""
        return {"report_type": report_type, "company_id": company_id, "status": "not_implemented"}

    def get_esg_schema(self, industry: str):
        """ì—…ì¢…ë³„ ESG ìŠ¤í‚¤ë§ˆ ì¡°íšŒ"""
        return {"industry": industry, "status": "not_implemented"}

    def get_esg_schema_by_industry(self, industry: str) -> Dict[str, Any]:
        """ì—…ì¢…ë³„ ESG ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì¡°íšŒ"""
        try:
            # ì—…ì¢…ë³„ ê¸°ë³¸ ESG ìŠ¤í‚¤ë§ˆ ì •ì˜
            schemas = {
                "ë°°í„°ë¦¬": {
                    "environmental": {
                        "carbon_footprint": {"required": True, "unit": "tCO2eq"},
                        "energy_consumption": {"required": True, "unit": "MWh"},
                        "water_usage": {"required": True, "unit": "m3"},
                        "waste_management": {"required": True, "unit": "ton"},
                        "recycled_materials": {"required": True, "unit": "%"}
                    },
                    "social": {
                        "labor_standards": {"required": True},
                        "safety_incidents": {"required": True},
                        "community_engagement": {"required": False}
                    },
                    "governance": {
                        "compliance_status": {"required": True},
                        "risk_management": {"required": True},
                        "transparency": {"required": False}
                    }
                },
                "í™”í•™ì†Œì¬": {
                    "environmental": {
                        "carbon_footprint": {"required": True, "unit": "tCO2eq"},
                        "chemical_emissions": {"required": True, "unit": "kg"},
                        "water_usage": {"required": True, "unit": "m3"},
                        "hazardous_waste": {"required": True, "unit": "ton"}
                    }
                }
            }
            
            if not industry:
                raise Exception("ì—…ì¢… ì •ë³´ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            
            if industry not in schemas:
                logger.warning(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì—…ì¢…: {industry}, ê¸°ë³¸ê°’(ë°°í„°ë¦¬) ì‚¬ìš©")
                industry = "ë°°í„°ë¦¬"
            
            return schemas[industry]
        except Exception as e:
            logger.error(f"ESG ìŠ¤í‚¤ë§ˆ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise Exception(f"ESG ìŠ¤í‚¤ë§ˆë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")

    # ===== ì‹¤ì œ DB í™˜ê²½ ë°ì´í„° ì¡°íšŒ ë©”ì„œë“œë“¤ =====

    def get_environmental_data_by_company(self, company_name: str) -> Dict[str, Any]:
        """íšŒì‚¬ë³„ ì‹¤ì œ í™˜ê²½ ë°ì´í„° ì¡°íšŒ (DBì—ì„œ ê³„ì‚°)"""
        try:
            if not self.db_available:
                logger.warning("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¶ˆê°€, ê¸°ë³¸ê°’ ë°˜í™˜")
                return self._get_default_environmental_data(company_name)
            
            # 1. normal í…Œì´ë¸”ì—ì„œ í•´ë‹¹ íšŒì‚¬ì˜ ë°ì´í„° ì¡°íšŒ
            normal_data = self.normal_repository.get_company_data(company_name)
            
            # 2. certification í…Œì´ë¸”ì—ì„œ ì˜¨ì‹¤ê°€ìŠ¤ ë§¤í•‘ ê²°ê³¼ ì¡°íšŒ
            certification_data = self.normal_repository.get_company_certifications(company_name)
            
            # 3. í™˜ê²½ ë°ì´í„° ê³„ì‚°
            environmental_data = self._calculate_environmental_data(normal_data, certification_data)
            
            return {
                "status": "success",
                "company_name": company_name,
                "data": environmental_data,
                "last_updated": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"í™˜ê²½ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨ ({company_name}): {e}")
            return {
                "status": "error",
                "message": f"í™˜ê²½ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {str(e)}",
                "data": self._get_default_environmental_data(company_name)
            }

    def _calculate_environmental_data(self, normal_data: List[Dict], certification_data: List[Dict]) -> Dict[str, Any]:
        """ì‹¤ì œ DB ë°ì´í„°ë¡œë¶€í„° í™˜ê²½ ë°ì´í„° ê³„ì‚°"""
        try:
            # íƒ„ì†Œë°°ì¶œëŸ‰ ê³„ì‚° (certification í…Œì´ë¸” ê¸°ë°˜)
            carbon_footprint = self._calculate_carbon_footprint(certification_data)
            
            # ì—ë„ˆì§€ì‚¬ìš©ëŸ‰ ê³„ì‚° (normal í…Œì´ë¸”ì˜ capacity, energy_density ê¸°ë°˜)
            energy_usage = self._calculate_energy_usage(normal_data)
            
            # ë¬¼ì‚¬ìš©ëŸ‰ ê³„ì‚° (normal í…Œì´ë¸”ì˜ raw_materials ê¸°ë°˜)
            water_usage = self._calculate_water_usage(normal_data)
            
            # íê¸°ë¬¼ ê´€ë¦¬ ê³„ì‚° (normal í…Œì´ë¸”ì˜ disposal_method, recycling_method ê¸°ë°˜)
            waste_management = self._calculate_waste_management(normal_data)
            
            # ì¸ì¦ ì •ë³´ ì¶”ì¶œ
            certifications = self._extract_certifications(normal_data)
            
            return {
                "carbonFootprint": carbon_footprint,
                "energyUsage": energy_usage,
                "waterUsage": water_usage,
                "wasteManagement": waste_management,
                "certifications": certifications
            }
            
        except Exception as e:
            logger.error(f"í™˜ê²½ ë°ì´í„° ê³„ì‚° ì‹¤íŒ¨: {e}")
            return self._get_default_environmental_data("Unknown")

    def _calculate_carbon_footprint(self, certification_data: List[Dict]) -> Dict[str, Any]:
        """ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ ê³„ì‚°"""
        try:
            total_scope1 = 0
            total_scope2 = 0
            total_scope3 = 0
            
            for cert in certification_data:
                if cert.get('final_mapped_sid'):
                    # ë§¤í•‘ëœ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ ê³„ì‚°
                    amount = float(cert.get('original_amount', 0))
                    
                    # SIDì— ë”°ë¥¸ Scope ë¶„ë¥˜
                    sid = cert.get('final_mapped_sid', '')
                    if 'CO2' in sid or 'CH4' in sid:
                        if 'direct' in sid.lower():
                            total_scope1 += amount
                        elif 'indirect' in sid.lower():
                            total_scope2 += amount
                        else:
                            total_scope3 += amount
                    else:
                        total_scope3 += amount
            
            total = total_scope1 + total_scope2 + total_scope3
            
            # íŠ¸ë Œë“œ ê³„ì‚° (ì„ì‹œë¡œ stable ë°˜í™˜)
            trend = 'stable'
            
            return {
                "total": round(total, 2),
                "trend": trend,
                "lastUpdate": datetime.now().strftime('%Y-%m-%d'),
                "breakdown": {
                    "scope1": round(total_scope1, 2),
                    "scope2": round(total_scope2, 2),
                    "scope3": round(total_scope3, 2)
                }
            }
            
        except Exception as e:
            logger.error(f"íƒ„ì†Œë°°ì¶œëŸ‰ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {
                "total": 0,
                "trend": "no_data",
                "lastUpdate": datetime.now().strftime('%Y-%m-%d'),
                "breakdown": {"scope1": 0, "scope2": 0, "scope3": 0},
                "message": "íƒ„ì†Œë°°ì¶œëŸ‰ ë°ì´í„°ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }

    def _calculate_energy_usage(self, normal_data: List[Dict]) -> Dict[str, Any]:
        """ì—ë„ˆì§€ì‚¬ìš©ëŸ‰ ê³„ì‚°"""
        try:
            total_energy = 0
            renewable_energy = 0
            
            for data in normal_data:
                # capacityì™€ energy_densityì—ì„œ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ì¶”ì •
                capacity = data.get('capacity', '0')
                energy_density = data.get('energy_density', '0')
                
                if capacity and energy_density:
                    try:
                        # ê°„ë‹¨í•œ ì—ë„ˆì§€ ê³„ì‚° (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ê³„ì‚° í•„ìš”)
                        energy_value = float(capacity.replace('Ah', '').replace('Wh', '')) * 0.1
                        total_energy += energy_value
                        
                        # recycled_materialì´ Trueë©´ ì¬ìƒì—ë„ˆì§€ë¡œ ê°„ì£¼
                        if data.get('recycled_material'):
                            renewable_energy += energy_value * 0.3
                    except:
                        pass
            
            # ì‹¤ì œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ 0 ë°˜í™˜ (ìƒ˜í”Œë°ì´í„° ì œê±°)
            if total_energy == 0:
                total_energy = 0
                renewable_energy = 0
            
            return {
                "total": round(total_energy, 2),
                "renewable": round(renewable_energy, 2),
                "trend": "up",
                "lastUpdate": datetime.now().strftime('%Y-%m-%d')
            }
            
        except Exception as e:
            logger.error(f"ì—ë„ˆì§€ì‚¬ìš©ëŸ‰ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {
                "total": 0,
                "renewable": 0,
                "trend": "no_data",
                "lastUpdate": datetime.now().strftime('%Y-%m-%d'),
                "message": "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë°ì´í„°ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }

    def _calculate_water_usage(self, normal_data: List[Dict]) -> Dict[str, Any]:
        """ë¬¼ì‚¬ìš©ëŸ‰ ê³„ì‚°"""
        try:
            total_water = 0
            recycled_water = 0
            
            for data in normal_data:
                # raw_materialsì—ì„œ ë¬¼ ì‚¬ìš©ëŸ‰ ì¶”ì •
                raw_materials = data.get('raw_materials', [])
                if raw_materials:
                    # ì›ì¬ë£Œ ì¢…ë¥˜ì— ë”°ë¥¸ ë¬¼ ì‚¬ìš©ëŸ‰ ì¶”ì •
                    material_count = len(raw_materials)
                    water_per_material = 100  # í†¤ë‹¹ ë¬¼ ì‚¬ìš©ëŸ‰ ì¶”ì •
                    total_water += material_count * water_per_material
                    
                    # recycled_materialì´ Trueë©´ ì¬í™œìš© ë¬¼ë¡œ ê°„ì£¼
                    if data.get('recycled_material'):
                        recycled_water += material_count * water_per_material * 0.3
            
            # ì‹¤ì œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ 0 ë°˜í™˜ (ìƒ˜í”Œë°ì´í„° ì œê±°)
            if total_water == 0:
                total_water = 0
                recycled_water = 0
            
            return {
                "total": round(total_water, 2),
                "recycled": round(recycled_water, 2),
                "trend": "stable",
                "lastUpdate": datetime.now().strftime('%Y-%m-%d')
            }
            
        except Exception as e:
            logger.error(f"ë¬¼ì‚¬ìš©ëŸ‰ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {
                "total": 0,
                "recycled": 0,
                "trend": "no_data",
                "lastUpdate": datetime.now().strftime('%Y-%m-%d'),
                "message": "ë¬¼ ì‚¬ìš©ëŸ‰ ë°ì´í„°ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }

    def _calculate_waste_management(self, normal_data: List[Dict]) -> Dict[str, Any]:
        """íê¸°ë¬¼ ê´€ë¦¬ ê³„ì‚°"""
        try:
            total_waste = 0
            recycled_waste = 0
            landfill_waste = 0
            
            for data in normal_data:
                # disposal_methodì™€ recycling_methodì—ì„œ íê¸°ë¬¼ ì •ë³´ ì¶”ì¶œ
                disposal_method = data.get('disposal_method', '')
                recycling_method = data.get('recycling_method', '')
                
                # ê¸°ë³¸ íê¸°ë¬¼ëŸ‰ ì¶”ì •
                base_waste = 50  # ê¸°ë³¸ íê¸°ë¬¼ëŸ‰
                total_waste += base_waste
                
                # ì¬í™œìš© ê°€ëŠ¥í•œ íê¸°ë¬¼ ì¶”ì •
                if recycling_method:
                    recycled_waste += base_waste * 0.7
                    landfill_waste += base_waste * 0.3
                else:
                    landfill_waste += base_waste
            
            # ì‹¤ì œ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ 0 ë°˜í™˜ (ìƒ˜í”Œë°ì´í„° ì œê±°)
            if total_waste == 0:
                total_waste = 0
                recycled_waste = 0
                landfill_waste = 0
            
            return {
                "total": round(total_waste, 2),
                "recycled": round(recycled_waste, 2),
                "landfill": round(landfill_waste, 2),
                "trend": "up",
                "lastUpdate": datetime.now().strftime('%Y-%m-%d')
            }
            
        except Exception as e:
            logger.error(f"íê¸°ë¬¼ ê´€ë¦¬ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return {
                "total": 0,
                "recycled": 0,
                "landfill": 0,
                "trend": "no_data",
                "lastUpdate": datetime.now().strftime('%Y-%m-%d'),
                "message": "íê¸°ë¬¼ ê´€ë¦¬ ë°ì´í„°ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }

    def _extract_certifications(self, normal_data: List[Dict]) -> List[str]:
        """ì¸ì¦ ì •ë³´ ì¶”ì¶œ"""
        try:
            certifications = []
            
            for data in normal_data:
                disposal_method = data.get('disposal_method', '')
                recycling_method = data.get('recycling_method', '')
                
                # ISO ì¸ì¦ ì •ë³´ ì¶”ì¶œ
                if 'ISO 14001' in disposal_method or 'ISO 14001' in recycling_method:
                    certifications.append('ISO 14001')
                if 'ISO 50001' in disposal_method or 'ISO 50001' in recycling_method:
                    certifications.append('ISO 50001')
                if 'OHSAS 18001' in disposal_method or 'OHSAS 18001' in recycling_method:
                    certifications.append('OHSAS 18001')
            
            # ì¤‘ë³µ ì œê±°
            certifications = list(set(certifications))
            
            # ì‹¤ì œ ì¸ì¦ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ìƒ˜í”Œë°ì´í„° ì œê±°)
            if not certifications:
                certifications = []
            
            return certifications
            
        except Exception as e:
            logger.error(f"ì¸ì¦ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []

    def _get_default_environmental_data(self, company_name: str) -> Dict[str, Any]:
        """ê¸°ë³¸ í™˜ê²½ ë°ì´í„° (DBì— ë°ì´í„°ê°€ ì—†ì„ ë•Œ ì‚¬ìš©)"""
        return {
            "carbonFootprint": {
                "total": 0,
                "trend": "no_data",
                "lastUpdate": datetime.now().strftime('%Y-%m-%d'),
                "breakdown": {"scope1": 0, "scope2": 0, "scope3": 0},
                "message": f"{company_name}ì˜ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            },
            "energyUsage": {
                "total": 0,
                "renewable": 0,
                "trend": "no_data",
                "lastUpdate": datetime.now().strftime('%Y-%m-%d'),
                "message": f"{company_name}ì˜ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            },
            "waterUsage": {
                "total": 0,
                "recycled": 0,
                "trend": "no_data",
                "lastUpdate": datetime.now().strftime('%Y-%m-%d'),
                "message": f"{company_name}ì˜ ë¬¼ ì‚¬ìš©ëŸ‰ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            },
            "wasteManagement": {
                "total": 0,
                "recycled": 0,
                "landfill": 0,
                "trend": "no_data",
                "lastUpdate": datetime.now().strftime('%Y-%m-%d'),
                "message": f"{company_name}ì˜ íê¸°ë¬¼ ê´€ë¦¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
            },
            "certifications": [],
            "message": f"{company_name}ì˜ í™˜ê²½ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
        }

    # ===== Substance Mapping ê´€ë ¨ ë©”ì„œë“œë“¤ =====
    
    def _load_model_and_data(self):
        """ëª¨ë¸ê³¼ ê·œì • ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            # í™˜ê²½ë³€ìˆ˜ì—ì„œ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
            MODEL_DIR = os.getenv("MODEL_DIR", "/app/model/bomi-ai")
            HF_REPO_ID = os.getenv("HF_REPO_ID", "galaxybuddy/bomi-ai")
            
            # BOMI AI ëª¨ë¸ ë¡œë“œ (ë¡œì»¬ ìš°ì„ )
            model_dir = Path(MODEL_DIR)
            
            model_loaded = False
            if model_dir.exists() and any(model_dir.glob("*.safetensors")):
                # ë¡œì»¬ ëª¨ë¸ì´ ìˆìœ¼ë©´ ì‚¬ìš©
                try:
                    self.model = SentenceTransformer(str(model_dir), local_files_only=True)
                    logger.info(f"BOMI AI ëª¨ë¸ ë¡œë“œ ì„±ê³µ (ë¡œì»¬): {model_dir}")
                    model_loaded = True
                except Exception as e:
                    logger.warning(f"ë¡œì»¬ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                    model_loaded = False
            
            if not model_loaded:
                # ë¡œì»¬ ëª¨ë¸ì´ ì—†ìœ¼ë©´ Hugging Faceì—ì„œ ë‹¤ìš´ë¡œë“œ
                try:
                    logger.info(f"Hugging Faceì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œë„: {HF_REPO_ID}")
                    self.model = SentenceTransformer(HF_REPO_ID)
                    logger.info(f"BOMI AI ëª¨ë¸ ë¡œë“œ ì„±ê³µ (Hugging Face): {HF_REPO_ID}")
                    model_loaded = True
                except Exception as e:
                    logger.error(f"Hugging Face ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
                    raise Exception(f"BOMI AI ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¡œì»¬: {MODEL_DIR}, Hugging Face: {HF_REPO_ID}")
                    
            # ê·œì • ë°ì´í„° ë¡œë“œ (ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ í‘œì¤€ ë°ì´í„°)
            self._load_regulation_data()
                
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def _load_regulation_data(self):
        """ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ í‘œì¤€ ê·œì • ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            # ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ í‘œì¤€ ë°ì´í„° (IPCC, K-ETS ê¸°ì¤€)
            regulation_data = [
                {"sid": "CO2_DIRECT", "name": "ì´ì‚°í™”íƒ„ì†Œ ì§ì ‘ë°°ì¶œ (Scope 1)"},
                {"sid": "CO2_INDIRECT", "name": "ì´ì‚°í™”íƒ„ì†Œ ê°„ì ‘ë°°ì¶œ (Scope 2)"},
                {"sid": "CO2_OTHER", "name": "ì´ì‚°í™”íƒ„ì†Œ ê¸°íƒ€ë°°ì¶œ (Scope 3)"},
                {"sid": "CH4_DIRECT", "name": "ë©”íƒ„ ì§ì ‘ë°°ì¶œ (Scope 1)"},
                {"sid": "CH4_INDIRECT", "name": "ë©”íƒ„ ê°„ì ‘ë°°ì¶œ (Scope 2)"},
                {"sid": "CH4_OTHER", "name": "ë©”íƒ„ ê¸°íƒ€ë°°ì¶œ (Scope 3)"},
                {"sid": "N2O_DIRECT", "name": "ì•„ì‚°í™”ì§ˆì†Œ ì§ì ‘ë°°ì¶œ (Scope 1)"},
                {"sid": "N2O_INDIRECT", "name": "ì•„ì‚°í™”ì§ˆì†Œ ê°„ì ‘ë°°ì¶œ (Scope 2)"},
                {"sid": "N2O_OTHER", "name": "ì•„ì‚°í™”ì§ˆì†Œ ê¸°íƒ€ë°°ì¶œ (Scope 3)"},
                {"sid": "HFC_DIRECT", "name": "ìˆ˜ì†Œë¶ˆí™”íƒ„ì†Œ ì§ì ‘ë°°ì¶œ (Scope 1)"},
                {"sid": "HFC_INDIRECT", "name": "ìˆ˜ì†Œë¶ˆí™”íƒ„ì†Œ ê°„ì ‘ë°°ì¶œ (Scope 2)"},
                {"sid": "PFC_DIRECT", "name": "ê³¼ë¶ˆí™”íƒ„ì†Œ ì§ì ‘ë°°ì¶œ (Scope 1)"},
                {"sid": "PFC_INDIRECT", "name": "ê³¼ë¶ˆí™”íƒ„ì†Œ ê°„ì ‘ë°°ì¶œ (Scope 2)"},
                {"sid": "SF6_DIRECT", "name": "ìœ¡ë¶ˆí™”í™© ì§ì ‘ë°°ì¶œ (Scope 1)"},
                {"sid": "SF6_INDIRECT", "name": "ìœ¡ë¶ˆí™”í™© ê°„ì ‘ë°°ì¶œ (Scope 2)"},
                {"sid": "NF3_DIRECT", "name": "ì‚¼ë¶ˆí™”ì§ˆì†Œ ì§ì ‘ë°°ì¶œ (Scope 1)"},
                {"sid": "NF3_INDIRECT", "name": "ì‚¼ë¶ˆí™”ì§ˆì†Œ ê°„ì ‘ë°°ì¶œ (Scope 2)"},
                {"sid": "CO2_TOTAL", "name": "ì´ì‚°í™”íƒ„ì†Œ ì´ë°°ì¶œëŸ‰"},
                {"sid": "CH4_TOTAL", "name": "ë©”íƒ„ ì´ë°°ì¶œëŸ‰"},
                {"sid": "N2O_TOTAL", "name": "ì•„ì‚°í™”ì§ˆì†Œ ì´ë°°ì¶œëŸ‰"},
                {"sid": "GHG_TOTAL", "name": "ì˜¨ì‹¤ê°€ìŠ¤ ì´ë°°ì¶œëŸ‰ (CO2eq)"},
                {"sid": "CO2_ENERGY", "name": "ì—ë„ˆì§€ ì‚¬ìš©ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_TRANSPORT", "name": "ìš´ì†¡ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_PROCESS", "name": "ê³µì •ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_WASTE", "name": "íê¸°ë¬¼ ì²˜ë¦¬ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_AGRICULTURE", "name": "ë†ì—…ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_FORESTRY", "name": "ì‚°ë¦¼ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_INDUSTRIAL", "name": "ì‚°ì—…ê³µì •ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_BUILDING", "name": "ê±´ë¬¼ ì—ë„ˆì§€ ì‚¬ìš©ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_ELECTRICITY", "name": "ì „ë ¥ ì‚¬ìš©ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_HEATING", "name": "ë‚œë°©ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_COOLING", "name": "ëƒ‰ë°©ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_MANUFACTURING", "name": "ì œì¡°ì—…ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_MINING", "name": "ì±„êµ´ì—…ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_CHEMICAL", "name": "í™”í•™ê³µì—…ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_METAL", "name": "ê¸ˆì†ê³µì—…ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_PAPER", "name": "ì œì§€ê³µì—…ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_FOOD", "name": "ì‹í’ˆê³µì—…ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_TEXTILE", "name": "ì„¬ìœ ê³µì—…ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_CONSTRUCTION", "name": "ê±´ì„¤ì—…ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_SERVICE", "name": "ì„œë¹„ìŠ¤ì—…ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_COMMERCIAL", "name": "ìƒì—…ìš©ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_RESIDENTIAL", "name": "ì£¼ê±°ìš©ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_PUBLIC", "name": "ê³µê³µìš©ìœ¼ë¡œ ì¸í•œ ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_OTHER_SCOPE1", "name": "ê¸°íƒ€ Scope 1 ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_OTHER_SCOPE2", "name": "ê¸°íƒ€ Scope 2 ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
                {"sid": "CO2_OTHER_SCOPE3", "name": "ê¸°íƒ€ Scope 3 ì´ì‚°í™”íƒ„ì†Œ ë°°ì¶œ"},
            ]
            
            # DataFrameìœ¼ë¡œ ë³€í™˜
            self.regulation_data = pd.DataFrame(regulation_data)
            self.regulation_sids = self.regulation_data['sid'].tolist()
            self.regulation_names = self.regulation_data['name'].tolist()
            
            logger.info(f"âœ… ê·œì • ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.regulation_data)}ê°œ í•­ëª©")
            
            # FAISS ì¸ë±ìŠ¤ êµ¬ì¶•
            self._build_faiss_index()
            
        except Exception as e:
            logger.error(f"âŒ ê·œì • ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ë°ì´í„°ë¡œ ì´ˆê¸°í™”
            self.regulation_data = pd.DataFrame(columns=["sid", "name"])
            self.regulation_sids = []
            self.regulation_names = []
            self.faiss_index = None

    def _build_faiss_index(self):
        """FAISS ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤."""
        try:
            if not self.regulation_names or not self.model:
                logger.warning("ê·œì • ë°ì´í„° ë˜ëŠ” ëª¨ë¸ì´ ì—†ì–´ FAISS ì¸ë±ìŠ¤ë¥¼ êµ¬ì¶•í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
                
            # ê·œì • ë°ì´í„° ì„ë² ë”© ìƒì„±
            passage_texts = [f"passage: {name}" for name in self.regulation_names]
            embeddings = self.model.encode(
                passage_texts, 
                normalize_embeddings=True, 
                batch_size=32, 
                show_progress_bar=False
            ).astype("float32")
            
            # FAISS ì¸ë±ìŠ¤ ìƒì„±
            dimension = embeddings.shape[1]
            self.faiss_index = faiss.IndexFlatIP(dimension)
            self.faiss_index.add(embeddings)
            
            logger.info(f"âœ… FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ (ì°¨ì›: {dimension}, í•­ëª©: {len(self.regulation_names)}ê°œ)")
            
        except Exception as e:
            logger.error(f"âŒ FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ì‹¤íŒ¨: {e}")
            self.faiss_index = None
    
    def _create_empty_result(self, substance_name: str, error_message: str) -> Dict:
        """ì—ëŸ¬ ë°œìƒ ì‹œ ë¹ˆ ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        return {
            "substance_name": substance_name,
            "mapped_sid": None,
            "mapped_name": None,
            "top1_score": 0.0,
            "margin": 0.0,
            "confidence": 0.0,
            "band": "not_mapped",
            "top5_candidates": [],
            "error": error_message,
            "status": "error"
        }
    
    def get_substance_mapping_statistics(self) -> Dict:
        """ë§¤í•‘ ì„œë¹„ìŠ¤ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        try:
            if self.db_available and self.normal_repository:
                return self.normal_repository.get_mapping_statistics()
            else:
                return {
                    "model_loaded": self.model is not None,
                    "regulation_data_count": len(self.regulation_data) if self.regulation_data is not None else 0,
                    "faiss_index_built": self.faiss_index is not None,
                    "service_status": "ready" if all([self.model, self.regulation_data, self.faiss_index]) else "not_ready"
                }
        except Exception as e:
            logger.error(f"ë§¤í•‘ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "total_mappings": 0,
                "auto_mapped": 0,
                "needs_review": 0,
                "user_reviewed": 0,
                "avg_confidence": 0.0
            }
    
    def get_saved_mappings(self, company_id: str = None, limit: int = 10) -> List[Dict[str, Any]]:
        """ì €ì¥ëœ ë§¤í•‘ ê²°ê³¼ ì¡°íšŒ"""
        try:
            if not self.db_available:
                raise Exception("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ì„œë¹„ìŠ¤ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
            
            if not self.normal_repository:
                raise Exception("ë°ì´í„° ì €ì¥ì†Œê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë¹„ìŠ¤ë¥¼ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”.")
            
            return self.normal_repository.get_saved_mappings(company_id, limit)
        except Exception as e:
            logger.error(f"ë§¤í•‘ ê²°ê³¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise Exception(f"ì €ì¥ëœ ë§¤í•‘ ê²°ê³¼ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
    
    def get_original_data(self, company_id: str = None, limit: int = 10) -> List[Dict[str, Any]]:
        """ì›ë³¸ ë°ì´í„° ì¡°íšŒ"""
        try:
            if not self.db_available:
                raise Exception("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ì„œë¹„ìŠ¤ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
            
            if not self.normal_repository:
                raise Exception("ë°ì´í„° ì €ì¥ì†Œê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë¹„ìŠ¤ë¥¼ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”.")
            
            return self.normal_repository.get_original_data(company_id, limit)
        except Exception as e:
            logger.error(f"ì›ë³¸ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise Exception(f"ì›ë³¸ ë°ì´í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
    
    def get_corrections(self, company_id: str = None, limit: int = 10) -> List[Dict[str, Any]]:
        """ì‚¬ìš©ì ìˆ˜ì • ë°ì´í„° ì¡°íšŒ"""
        try:
            if not self.db_available:
                raise Exception("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ì„œë¹„ìŠ¤ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
            
            if not self.normal_repository:
                raise Exception("ë°ì´í„° ì €ì¥ì†Œê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë¹„ìŠ¤ë¥¼ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”.")
            
            # í˜„ì¬ëŠ” certification í…Œì´ë¸”ì—ì„œ user_reviewed ìƒíƒœì¸ ê²ƒë“¤ì„ ì¡°íšŒ
            mappings = self.normal_repository.get_saved_mappings(company_id, limit)
            return [m for m in mappings if m.get('mapping_status') == 'user_reviewed']
        except Exception as e:
            logger.error(f"ìˆ˜ì • ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            raise Exception(f"ì‚¬ìš©ì ìˆ˜ì • ë°ì´í„°ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
    
    def correct_mapping(self, certification_id: int, correction_data: Dict[str, Any]) -> bool:
        """ë§¤í•‘ ê²°ê³¼ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ìˆ˜ì •"""
        try:
            if not self.db_available:
                raise Exception("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ì„œë¹„ìŠ¤ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
            
            if not self.normal_repository:
                raise Exception("ë°ì´í„° ì €ì¥ì†Œê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë¹„ìŠ¤ë¥¼ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”.")
            
            return self.normal_repository.update_user_mapping_correction(
                certification_id, correction_data
            )
        except Exception as e:
            logger.error(f"ë§¤í•‘ ìˆ˜ì • ì‹¤íŒ¨: {e}")
            raise Exception(f"ë§¤í•‘ ê²°ê³¼ë¥¼ ìˆ˜ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
from eripotter_common.database.base import get_db_engine
import logging
from datetime import datetime
from typing import Dict, List
from ..repository.substance_mapping_repository import SubstanceMappingRepository
from .substance_mapping_service import SubstanceMappingService
from .data_normalization_service import DataNormalizationService

from .interfaces import ISubstanceMapping, IDataNormalization, IESGValidation

logger = logging.getLogger("normal-service")

class NormalService(ISubstanceMapping, IDataNormalization, IESGValidation):
    """í†µí•© Normal ì„œë¹„ìŠ¤ - ê¸°ëŠ¥ë³„ ì„œë¹„ìŠ¤ë“¤ì„ ì¡°ìœ¨"""
    
    def __init__(self):
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ ì„ íƒì ìœ¼ë¡œ ì‹œë„
        self.engine = None
        self.substance_mapping_repository = None
        self.db_available = False
        
        try:
            self.engine = get_db_engine()
            self.substance_mapping_repository = SubstanceMappingRepository(self.engine)
            self.db_available = True
            logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
        except Exception as e:
            logger.warning(f"âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            logger.info("ğŸ“ AI ë§¤í•‘ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤ (ê²°ê³¼ ì €ì¥ ë¶ˆê°€)")
        
        # ê¸°ëŠ¥ë³„ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.substance_mapping_service = SubstanceMappingService()
        self.data_normalization_service = DataNormalizationService()


    def get_all_normalized_data(self):
        """ëª¨ë“  ì •ê·œí™” ë°ì´í„° ì¡°íšŒ"""
        return []

    def get_normalized_data_by_id(self, data_id: str):
        """íŠ¹ì • ì •ê·œí™” ë°ì´í„° ì¡°íšŒ"""
        return {"id": data_id}

    def upload_and_normalize_excel(self, file):
        """ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ ë° AI ìë™ ë§¤í•‘"""
        try:
            logger.info(f"ğŸ“ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ: {file.filename}")
            
            # íŒŒì¼ ë‚´ìš© ì½ê¸°
            content = file.file.read()
            
            # 1ë‹¨ê³„: ë°ì´í„° ì •ê·œí™”
            normalization_result = self.data_normalization_service.normalize_excel_data(
                file_data=content,
                filename=file.filename
            )
            
            if normalization_result['status'] == 'error':
                return normalization_result
            
            # 2ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ì— ì›ë³¸ ë°ì´í„° ì €ì¥
            upload_result = {"status": "database_not_available"}
            if self.db_available:
                try:
                    upload_result = self.substance_mapping_repository.save_original_data(
                        filename=file.filename,
                        data=normalization_result['normalized_data'],
                        file_size=len(content)
                    )
                    logger.info("ğŸ’¾ ì›ë³¸ ë°ì´í„°ë¥¼ normal í…Œì´ë¸”ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤")
                except Exception as e:
                    logger.warning(f"âš ï¸ ì›ë³¸ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
                    upload_result = {"error": str(e)}
            
            # 3ë‹¨ê³„: AI ìë™ ë§¤í•‘ ìˆ˜í–‰
            substance_names = [row['substance_name'] for row in normalization_result['normalized_data']]
            mapping_results = []
            
            if substance_names:
                logger.info(f"ğŸ¤– AI ìë™ ë§¤í•‘ ì‹œì‘: {len(substance_names)}ê°œ ë¬¼ì§ˆ")
                mapping_results = self.map_substances_batch(substance_names)
                logger.info(f"âœ… AI ìë™ ë§¤í•‘ ì™„ë£Œ: {len(mapping_results)}ê°œ ê²°ê³¼")
            
            return {
                "filename": file.filename,
                "status": "uploaded_and_mapped",
                "normalization": normalization_result,
                "mapping_results": mapping_results,
                "database_save": upload_result,
                "message": "ì›ë³¸ ë°ì´í„°ëŠ” normal í…Œì´ë¸”, AI ë§¤í•‘ ê²°ê³¼ëŠ” certification í…Œì´ë¸”ì— ì €ì¥ë©ë‹ˆë‹¤"
            }
            
        except Exception as e:
            logger.error(f"âŒ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ ë° ë§¤í•‘ ì‹¤íŒ¨: {e}")
            return {
                "filename": file.filename,
                "status": "error",
                "error": str(e)
            }

    def create_normalized_data(self, data: dict):
        """ì •ê·œí™” ë°ì´í„° ìƒì„±"""
        return data

    def update_normalized_data(self, data_id: str, data: dict):
        """ì •ê·œí™” ë°ì´í„° ì—…ë°ì´íŠ¸"""
        return {"id": data_id, **data}

    def delete_normalized_data(self, data_id: str):
        """ì •ê·œí™” ë°ì´í„° ì‚­ì œ"""
        return True

    def get_metrics(self):
        """ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        return {}
    
    # ===== ë¬¼ì§ˆ ë§¤í•‘ ê´€ë ¨ ë©”ì„œë“œë“¤ =====
    
    # ===== ISubstanceMapping ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„ =====
    
    def map_substance(self, substance_name: str, company_id: str = None) -> dict:
        """ë‹¨ì¼ ë¬¼ì§ˆ ë§¤í•‘"""
        try:
            logger.info(f"ğŸ“ ë¬¼ì§ˆ ë§¤í•‘ ìš”ì²­: {substance_name}")
            
            # AI ë§¤í•‘ ìˆ˜í–‰
            mapping_result = self.substance_mapping_service.map_substance(substance_name)
            
            # íšŒì‚¬ ì •ë³´ ì¶”ê°€
            if company_id:
                mapping_result['company_id'] = company_id
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— ê²°ê³¼ ì €ì¥
            if mapping_result['status'] == 'success' and self.db_available:
                self.substance_mapping_repository.save_mapping_result(mapping_result)
            
            logger.info(f"âœ… ë¬¼ì§ˆ ë§¤í•‘ ì™„ë£Œ: {substance_name} -> {mapping_result.get('mapped_name', 'None')}")
            return mapping_result
            
        except Exception as e:
            logger.error(f"âŒ ë¬¼ì§ˆ ë§¤í•‘ ì‹¤íŒ¨: {e}")
            return {
                "substance_name": substance_name,
                "status": "error",
                "error": str(e)
            }
    
    def map_substances_batch(self, substance_names: list, company_id: str = None) -> list:
        """ë°°ì¹˜ ë¬¼ì§ˆ ë§¤í•‘"""
        try:
            logger.info(f"ğŸ“ ë°°ì¹˜ ë¬¼ì§ˆ ë§¤í•‘ ìš”ì²­: {len(substance_names)}ê°œ")
            
            results = []
            for substance_name in substance_names:
                result = self.map_substance(substance_name, company_id)
                results.append(result)
            
            logger.info(f"âœ… ë°°ì¹˜ ë¬¼ì§ˆ ë§¤í•‘ ì™„ë£Œ: {len(results)}ê°œ")
            return results
            
        except Exception as e:
            logger.error(f"âŒ ë°°ì¹˜ ë¬¼ì§ˆ ë§¤í•‘ ì‹¤íŒ¨: {e}")
            return []
    
    def map_file(self, file_path: str) -> dict:
        """íŒŒì¼ì—ì„œ ë¬¼ì§ˆ ë§¤í•‘"""
        try:
            logger.info(f"ğŸ“ íŒŒì¼ ë§¤í•‘ ìš”ì²­: {file_path}")
            
            # íŒŒì¼ ë§¤í•‘ ìˆ˜í–‰
            result = self.substance_mapping_service.map_file(file_path)
            
            # ì„±ê³µí•œ ë§¤í•‘ ê²°ê³¼ë“¤ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            if result['status'] == 'success':
                for mapping_result in result.get('mapping_results', []):
                    if mapping_result['status'] == 'success':
                        self.substance_mapping_repository.save_mapping_result(mapping_result)
            
            logger.info(f"âœ… íŒŒì¼ ë§¤í•‘ ì™„ë£Œ: {file_path}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ë§¤í•‘ ì‹¤íŒ¨: {e}")
            return {
                "file_path": file_path,
                "status": "error",
                "error": str(e)
            }
    
    def get_mapping_statistics(self) -> dict:
        """ë¬¼ì§ˆ ë§¤í•‘ í†µê³„ ì¡°íšŒ"""
        try:
            # AI ì„œë¹„ìŠ¤ í†µê³„
            ai_stats = self.substance_mapping_service.get_mapping_statistics()
            
            # ë°ì´í„°ë² ì´ìŠ¤ í†µê³„
            db_stats = self.substance_mapping_repository.get_mapping_statistics()
            
            # í†µí•© í†µê³„
            combined_stats = {
                "ai_service": ai_stats,
                "database": db_stats,
                "timestamp": datetime.now().isoformat()
            }
            
            logger.info("âœ… ë¬¼ì§ˆ ë§¤í•‘ í†µê³„ ì¡°íšŒ ì™„ë£Œ")
            return combined_stats
            
        except Exception as e:
            logger.error(f"âŒ ë¬¼ì§ˆ ë§¤í•‘ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    # ===== IDataNormalization ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„ =====
    
    def normalize_excel_data(self, file_data: bytes, filename: str, company_id: str = None) -> Dict:
        """ì—‘ì…€ ë°ì´í„° ì •ê·œí™”"""
        return self.data_normalization_service.normalize_excel_data(file_data, filename, company_id)
    
    def validate_data_structure(self, data: Dict) -> Dict:
        """ë°ì´í„° êµ¬ì¡° ê²€ì¦"""
        return self.data_normalization_service.validate_data_structure(data)
    
    def standardize_data(self, data: Dict) -> Dict:
        """ë°ì´í„° í‘œì¤€í™”"""
        return self.data_normalization_service.standardize_data(data)
    
    # ===== IESGValidation ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„ =====
    
    def validate_esg_data(self, data: Dict, industry: str = None) -> Dict:
        """ESG ë°ì´í„° ê²€ì¦"""
        return self.esg_validation_service.validate_esg_data(data, industry)
    
    def calculate_esg_score(self, data: Dict) -> int:
        """ESG ì ìˆ˜ ê³„ì‚°"""
        return self.esg_validation_service.calculate_esg_score(data)
    
    def generate_esg_report(self, company_id: str, report_type: str) -> Dict:
        """ESG ë³´ê³ ì„œ ìƒì„±"""
        return self.esg_validation_service.generate_esg_report(company_id, report_type)
    
    def correct_mapping(self, mapping_id: int, correction_data: dict) -> bool:
        """ë§¤í•‘ ê²°ê³¼ ìˆ˜ë™ ìˆ˜ì •"""
        try:
            logger.info(f"ğŸ“ ë§¤í•‘ ìˆ˜ì • ìš”ì²­: mapping_id {mapping_id}")
            
            # ìˆ˜ì • ë°ì´í„° ê²€ì¦
            required_fields = ["corrected_sid", "corrected_name", "correction_reason"]
            for field in required_fields:
                if field not in correction_data:
                    logger.error(f"âŒ í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
                    return False
            
            # ìˆ˜ì • ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            if self.db_available:
                success = self.substance_mapping_repository.save_mapping_correction(mapping_id, correction_data)
                
                if success:
                    logger.info(f"âœ… ë§¤í•‘ ìˆ˜ì • ì™„ë£Œ: mapping_id {mapping_id}")
                    logger.info(f"   - ìˆ˜ì •ëœ SID: {correction_data['corrected_sid']}")
                    logger.info(f"   - ìˆ˜ì •ëœ ì´ë¦„: {correction_data['corrected_name']}")
                    logger.info(f"   - ìˆ˜ì • ì´ìœ : {correction_data['correction_reason']}")
                else:
                    logger.error(f"âŒ ë§¤í•‘ ìˆ˜ì • ì‹¤íŒ¨: mapping_id {mapping_id}")
                
                return success
            else:
                logger.warning("âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¶ˆê°€ë¡œ ìˆ˜ì • ì‚¬í•­ì„ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return False
            
        except Exception as e:
            logger.error(f"âŒ ë§¤í•‘ ìˆ˜ì • ì‹¤íŒ¨: {e}")
            return False

    # ===== í˜‘ë ¥ì‚¬ ESG ë°ì´í„° ê´€ë ¨ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ =====

    def upload_partner_esg_file(self, file, company_id: str = None):
        """í˜‘ë ¥ì‚¬ ESG ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬"""
        import uuid
        
        # ì—…ë¡œë“œ ID ìƒì„±
        upload_id = str(uuid.uuid4())
        
        # íŒŒì¼ ì •ë³´ ì €ì¥ (ì‹¤ì œë¡œëŠ” DBì— ì €ì¥)
        file_info = {
            "upload_id": upload_id,
            "filename": file.filename,
            "size": file.size,
            "company_id": company_id,
            "upload_time": datetime.now().isoformat(),
            "status": "uploaded"
        }
        
        # íŒŒì¼ ë‚´ìš© ì½ê¸° (ì‹¤ì œë¡œëŠ” íŒŒì¼ ì‹œìŠ¤í…œì— ì €ì¥)
        content = file.file.read()
        
        # ë¡œê¹…
        logger.info(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {file.filename} (í¬ê¸°: {file.size} bytes)")
        
        return file_info

    def validate_partner_esg_data(self, data: dict):
        """í˜‘ë ¥ì‚¬ ESG ë°ì´í„° ê²€ì¦ ë° í‘œì¤€í™”"""
        validation_result = {
            "is_valid": True,
            "issues": [],
            "standardized_data": {},
            "esg_score": 0,
            "completion_rate": 0
        }
        
        # ESG ë°ì´í„° ê²€ì¦ ë¡œì§
        required_fields = ["environmental", "social", "governance"]
        
        for field in required_fields:
            if field not in data:
                validation_result["is_valid"] = False
                validation_result["issues"].append({
                    "field": field,
                    "message": f"{field} ë°ì´í„°ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."
                })
        
        # ESG ì ìˆ˜ ê³„ì‚° (ì˜ˆì‹œ)
        if validation_result["is_valid"]:
            validation_result["esg_score"] = self._calculate_esg_score(data)
            validation_result["completion_rate"] = self._calculate_completion_rate(data)
            validation_result["standardized_data"] = self._standardize_esg_data(data)
        
        return validation_result

    def get_partner_dashboard_data(self, company_id: str):
        """í˜‘ë ¥ì‚¬ ESG ìê°€ì§„ë‹¨ ëŒ€ì‹œë³´ë“œ ë°ì´í„° ì¡°íšŒ"""
        # ì‹¤ì œë¡œëŠ” DBì—ì„œ ì¡°íšŒ
        dashboard_data = {
            "company_id": company_id,
            "esg_score": 87,
            "completion_rate": 80,  # 24/30
            "improvement_items": 6,
            "next_deadline": "2024-02-15",
            "categories": {
                "environmental": {
                    "score": 85,
                    "completed_items": ["íƒ„ì†Œ ë°°ì¶œëŸ‰", "íê¸°ë¬¼ ê´€ë¦¬"],
                    "in_progress": ["ì—ë„ˆì§€ íš¨ìœ¨ì„±"],
                    "not_started": []
                },
                "social": {
                    "score": 75,
                    "completed_items": ["ë…¸ë™ ì¡°ê±´"],
                    "in_progress": ["ì»¤ë®¤ë‹ˆí‹° ì°¸ì—¬"],
                    "not_started": ["ê³µê¸‰ë§ ê´€ë¦¬"]
                },
                "governance": {
                    "score": 90,
                    "completed_items": ["ì´ì‚¬íšŒ êµ¬ì„±", "ìœ¤ë¦¬ ê²½ì˜"],
                    "in_progress": ["íˆ¬ëª…ì„±"],
                    "not_started": []
                }
            }
        }
        
        return dashboard_data

    def generate_partner_esg_report(self, report_type: str, company_id: str):
        """í˜‘ë ¥ì‚¬ ESG ë³´ê³ ì„œ ìë™ ìƒì„±"""
        report_data = {
            "report_id": f"REP_{company_id}_{report_type}_{int(datetime.now().timestamp())}",
            "company_id": company_id,
            "report_type": report_type,
            "generated_at": datetime.now().isoformat(),
            "content": {
                "summary": f"{company_id}ì˜ {report_type} ë³´ê³ ì„œ",
                "esg_score": 87,
                "recommendations": [
                    "ê³µê¸‰ë§ ê´€ë¦¬ ê°•í™” í•„ìš”",
                    "ì—ë„ˆì§€ íš¨ìœ¨ì„± ê°œì„  ê¶Œì¥",
                    "íˆ¬ëª…ì„± ì œê³  ë°©ì•ˆ ê²€í† "
                ]
            }
        }
        
        return report_data

    def get_esg_schema_by_industry(self, industry: str):
        """ì—…ì¢…ë³„ ESG ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì¡°íšŒ"""
        schemas = {
            "general": {
                "environmental": ["íƒ„ì†Œ ë°°ì¶œëŸ‰", "ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰", "íê¸°ë¬¼ ê´€ë¦¬", "ìˆ˜ìì› ê´€ë¦¬"],
                "social": ["ë…¸ë™ ì¡°ê±´", "ì•ˆì „ ê´€ë¦¬", "ê³µê¸‰ë§ ê´€ë¦¬", "ì»¤ë®¤ë‹ˆí‹° ì°¸ì—¬"],
                "governance": ["ì´ì‚¬íšŒ êµ¬ì„±", "ìœ¤ë¦¬ ê²½ì˜", "íˆ¬ëª…ì„±", "ë¦¬ìŠ¤í¬ ê´€ë¦¬"]
            },
            "battery": {
                "environmental": ["ë°°í„°ë¦¬ ì¬í™œìš©", "í¬í† ë¥˜ ê´€ë¦¬", "ì—ë„ˆì§€ íš¨ìœ¨ì„±", "íƒ„ì†Œ ë°°ì¶œëŸ‰"],
                "social": ["ì•ˆì „ ê´€ë¦¬", "ê³µê¸‰ë§ íˆ¬ëª…ì„±", "ë…¸ë™ ì¡°ê±´", "ì§€ì—­ ì‚¬íšŒ ê¸°ì—¬"],
                "governance": ["ì´ì‚¬íšŒ ë‹¤ì–‘ì„±", "ìœ¤ë¦¬ ê²½ì˜", "íˆ¬ëª…ì„±", "ì§€ì†ê°€ëŠ¥ì„± ì •ì±…"]
            },
            "chemical": {
                "environmental": ["í™”í•™ ë¬¼ì§ˆ ê´€ë¦¬", "íìˆ˜ ì²˜ë¦¬", "ëŒ€ê¸° ì˜¤ì—¼ ê´€ë¦¬", "ì•ˆì „ ê´€ë¦¬"],
                "social": ["ì•ˆì „ êµìœ¡", "ê³µê¸‰ë§ ê´€ë¦¬", "ì§€ì—­ ì‚¬íšŒ ê´€ê³„", "ë…¸ë™ ì¡°ê±´"],
                "governance": ["ì•ˆì „ ì •ì±…", "ìœ¤ë¦¬ ê²½ì˜", "íˆ¬ëª…ì„±", "ë¦¬ìŠ¤í¬ ê´€ë¦¬"]
            }
        }
        
        return schemas.get(industry, schemas["general"])

    def _calculate_esg_score(self, data: dict) -> int:
        """ESG ì ìˆ˜ ê³„ì‚°"""
        # ê°„ë‹¨í•œ ì ìˆ˜ ê³„ì‚° ë¡œì§ (ì‹¤ì œë¡œëŠ” ë” ë³µì¡í•œ ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©)
        score = 0
        total_items = 0
        
        for category in ["environmental", "social", "governance"]:
            if category in data:
                category_data = data[category]
                if isinstance(category_data, dict):
                    score += len(category_data) * 10
                    total_items += len(category_data)
        
        return min(100, score) if total_items > 0 else 0

    def _calculate_completion_rate(self, data: dict) -> int:
        """ì™„ë£Œìœ¨ ê³„ì‚°"""
        completed = 0
        total = 30  # ì´ 30ê°œ í•­ëª©
        
        for category in ["environmental", "social", "governance"]:
            if category in data:
                category_data = data[category]
                if isinstance(category_data, dict):
                    completed += len(category_data)
        
        return min(100, int((completed / total) * 100))

    def _standardize_esg_data(self, data: dict) -> dict:
        """ESG ë°ì´í„° í‘œì¤€í™”"""
        standardized = {}
        
        # ë°ì´í„° í‘œì¤€í™” ë¡œì§
        for category, category_data in data.items():
            if isinstance(category_data, dict):
                standardized[category] = {}
                for key, value in category_data.items():
                    # í‚¤ ì´ë¦„ í‘œì¤€í™”
                    standardized_key = self._standardize_field_name(key)
                    standardized[category][standardized_key] = value
        
        return standardized

    def _standardize_field_name(self, field_name: str) -> str:
        """í•„ë“œëª… í‘œì¤€í™”"""
        # ê°„ë‹¨í•œ í‘œì¤€í™” ë¡œì§
        field_mapping = {
            "íƒ„ì†Œë°°ì¶œëŸ‰": "carbon_emissions",
            "ì—ë„ˆì§€íš¨ìœ¨ì„±": "energy_efficiency",
            "íê¸°ë¬¼ê´€ë¦¬": "waste_management",
            "ë…¸ë™ì¡°ê±´": "labor_conditions",
            "ê³µê¸‰ë§ê´€ë¦¬": "supply_chain_management",
            "ì´ì‚¬íšŒêµ¬ì„±": "board_composition",
            "ìœ¤ë¦¬ê²½ì˜": "ethical_management"
        }
        
        return field_mapping.get(field_name, field_name)
"""
ê³µí†µ RAG ìœ í‹¸ë¦¬í‹° (ì„œë¹„ìŠ¤ ë‚´ ì¬ì‚¬ìš©)
- EMBEDDER, OPENAI_MODEL ë“± í™˜ê²½ë³€ìˆ˜ë¡œ ë™ì‘ ì œì–´
- QdrantëŠ” URLì„ host/portë¡œ íŒŒì‹±í•´ HTTPS + HTTPë§Œ(prefer_grpc=False)
- í¬ì¸íŠ¸ IDëŠ” UUIDv5ë¡œ ì•ˆì • ìƒì„±
"""
from typing import List, Dict, Any, Optional
import os
import logging
from urllib.parse import urlparse
from uuid import uuid5, NAMESPACE_URL

from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct, Filter, FieldCondition, MatchValue, PointIdsList

logger = logging.getLogger(__name__)

# ===== ì„ë² ë” ì„ íƒ =====
def _get_embedder():
    """
    EMBEDDER=bge-m3|minilm|openai
    - bge-m3: 1024ì°¨ì› (SentenceTransformer í•„ìš”)
    - minilm: 384ì°¨ì› (SentenceTransformer í•„ìš”)
    - openai: 1536ì°¨ì› (OpenAI Embeddings)
    """
    emb = os.getenv("EMBEDDER", "bge-m3").lower()  # ê¸°ë³¸ê°’ bge-m3 (Qdrant 1024ê³¼ ì¼ì¹˜ ê°€ì •)

    # sentence-transformers ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸
    try:
        import sentence_transformers  # noqa: F401
        logger.info("âœ… sentence-transformers ì„¤ì¹˜ë¨")
        sentence_transformers_available = True
    except ImportError:
        logger.warning("âŒ sentence-transformers ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
        sentence_transformers_available = False

    if emb == "bge-m3":
        # âš ï¸ bge-m3 ì‚¬ìš© ì‹œì—ëŠ” ë°˜ë“œì‹œ sentence-transformers(+torch)ê°€ í•„ìš”
        if not sentence_transformers_available:
            raise RuntimeError(
                "EMBEDDER=bge-m3 ì´ì§€ë§Œ sentence-transformers ë¯¸ì„¤ì¹˜. "
                "pip install sentence-transformers torch transformers "
                "ë˜ëŠ” ì»¬ë ‰ì…˜ì„ 1536ì°¨ì›ìœ¼ë¡œ ì¬ìƒ‰ì¸ í›„ EMBEDDER=openai ì‚¬ìš©."
            )
        try:
            from sentence_transformers import SentenceTransformer
            logger.info("ğŸ”§ bge-m3 ì„ë² ë” ì´ˆê¸°í™” ì¤‘...")
            m = SentenceTransformer("BAAI/bge-m3")
            dim = 1024
            def encode(texts: List[str]) -> List[List[float]]:
                # bge-m3 ê¶Œì¥: ì¿¼ë¦¬ ì ‘ë‘ì–´
                return m.encode([f"query: {t}" for t in texts], normalize_embeddings=True).tolist()
            logger.info("âœ… bge-m3 ì„ë² ë” ì´ˆê¸°í™” ì™„ë£Œ")
            return encode, dim, "bge-m3"
        except Exception as e:
            logger.error(f"âŒ bge-m3 ì„ë² ë” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    elif emb == "minilm":
        if not sentence_transformers_available:
            raise RuntimeError("EMBEDDER=minilm ì´ì§€ë§Œ sentence-transformers ë¯¸ì„¤ì¹˜.")
        try:
            from sentence_transformers import SentenceTransformer
            m = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
            dim = 384
            def encode(texts: List[str]) -> List[List[float]]:
                return m.encode(texts, normalize_embeddings=True).tolist()
            return encode, dim, "minilm"
        except Exception as e:
            logger.error(f"âŒ minilm ì„ë² ë” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    elif emb == "openai":
        return _get_openai_embedder()

    else:
        logger.warning(f"Unknown EMBEDDER: {emb}, falling back to openai")
        return _get_openai_embedder()


def _get_openai_embedder():
    """OpenAI ì„ë² ë” ì„¤ì • (1536ì°¨ì›)."""
    # âœ… ë°©ì–´: í˜¹ì‹œ ë‚¨ì•„ ìˆì„ì§€ ëª¨ë¥´ëŠ” í”„ë¡ì‹œ ENV ë¬´ì‹œ
    for k in ("OPENAI_PROXY", "HTTP_PROXY", "HTTPS_PROXY", "http_proxy", "https_proxy", "ALL_PROXY"):
        os.environ.pop(k, None)

    from openai import OpenAI
    try:
        client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])
        model = os.getenv("OPENAI_EMBED_MODEL", "text-embedding-3-small")  # 1536ì°¨ì›
        dim = 1536
        def encode(texts: List[str]) -> List[List[float]]:
            out = client.embeddings.create(model=model, input=texts)
            return [e.embedding for e in out.data]
        return encode, dim, "openai"
    except Exception as e:
        logger.error(f"OpenAI ì„ë² ë” ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise


# ===== LLM (ì„ íƒ) =====
def _get_llm():
    from langchain_openai import ChatOpenAI
    # âœ… ë°©ì–´: í”„ë¡ì‹œ ENV ë¬´ì‹œ (OpenAI 1.x 'proxies' ì¸ì ë¯¸ì§€ì› ì´ìŠˆ íšŒí”¼)
    for k in ("OPENAI_PROXY", "HTTP_PROXY", "HTTPS_PROXY", "http_proxy", "https_proxy", "ALL_PROXY"):
        os.environ.pop(k, None)

    model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
    try:
        # ëª…ì‹œì ìœ¼ë¡œ í—ˆìš©ëœ íŒŒë¼ë¯¸í„°ë§Œ ì „ë‹¬
        llm_params = {
            "model": model,
            "temperature": 0.7,
            "openai_api_key": os.getenv("OPENAI_API_KEY")
        }
        
        return ChatOpenAI(**llm_params)
    except Exception as e:
        logger.error(f"ChatOpenAI ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise


# ===== ìœ í‹¸ ë³¸ì²´ =====
class RAGUtils:
    def __init__(self, collection_name: Optional[str] = None):
        qurl = os.getenv("QDRANT_URL", "https://qdrant-production-1efa.up.railway.app")
        # âœ… í‚¤ ì´ë¦„ í˜¸í™˜ (Railway í™˜ê²½ë³€ìˆ˜ì™€ ë§¤ì¹­)
        key = os.getenv("QDRANT_API_KEY") or os.getenv("QDRANT_SERVICE_API_KEY") or os.getenv("QDRANT__SERVICE__API_KEY")
        p = urlparse(qurl)
        self.qdrant_client = QdrantClient(
            host=p.hostname,
            port=p.port or (443 if p.scheme == "https" else 80),
            https=(p.scheme == "https"),
            api_key=key,
            prefer_grpc=False,
            timeout=60,
        )

        # ì„ë² ë”ëŠ” í•„ìš”í•  ë•Œë§Œ ì´ˆê¸°í™”
        self._encode = None
        self._dim = None
        self._embedder_name = None
        self.collection_name = collection_name or os.getenv("QDRANT_COLLECTION", "documents")
        self._ensure_collection_exists()
        self._llm = None

    @property
    def encode(self):
        """ì„ë² ë” lazy loading"""
        if self._encode is None:
            self._encode, self._dim, self._embedder_name = _get_embedder()
        return self._encode

    @property
    def dim(self):
        """ì„ë² ë” ì°¨ì› lazy loading"""
        if self._dim is None:
            self._encode, self._dim, self._embedder_name = _get_embedder()
        return self._dim

    @property
    def embedder_name(self):
        """ì„ë² ë” ì´ë¦„ lazy loading"""
        if self._embedder_name is None:
            self._encode, self._dim, self._embedder_name = _get_embedder()
        return self._embedder_name

    def _ensure_collection_exists(self):
        try:
            logger.info(f"ğŸ” Qdrant ì»¬ë ‰ì…˜ í™•ì¸: '{self.collection_name}'")
            info = self.qdrant_client.get_collection(self.collection_name)
            logger.info(f"âœ… ì»¬ë ‰ì…˜ ì¡´ì¬ í™•ì¸: '{self.collection_name}'")

            # ì°¨ì› ê²€ì¦ & ì»¬ë ‰ì…˜ ì°¨ì›ì— ë§ê²Œ EMBEDDER ê°•ì œ
            actual = None
            try:
                # Qdrant ë²„ì „ì— ë”°ë¼ vectorsê°€ ë‹¨ì¼/ë©€í‹°ì¼ ìˆ˜ ìˆìŒ
                vectors = info.config.params.vectors
                if hasattr(vectors, "size"):
                    actual = vectors.size
                elif isinstance(vectors, dict):
                    first = next(iter(vectors.values()))
                    actual = getattr(first, "size", None)
            except Exception:
                pass

            if actual:
                logger.info(f"ğŸ“Š ì»¬ë ‰ì…˜ ë²¡í„° ì°¨ì›: {actual}")
                if actual == 1024:
                    os.environ["EMBEDDER"] = "bge-m3"
                    logger.info("ğŸ”§ EMBEDDERë¥¼ bge-m3ë¡œ ì„¤ì • (1024ì°¨ì›)")
                elif actual == 1536:
                    os.environ["EMBEDDER"] = "openai"
                    logger.info("ğŸ”§ EMBEDDERë¥¼ openaië¡œ ì„¤ì • (1536ì°¨ì›)")
                else:
                    logger.warning(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì°¨ì›: {actual} (ì§€ì›: 1024=bge-m3, 1536=openai)")

                # ê¸°ëŒ€ ì°¨ì›ê³¼ ë‹¤ë¥´ë©´ ê²½ê³  (ì´ ì‹œì ì—ì„œ self.dimì€ ê°•ì œëœ EMBEDDER ê¸°ì¤€)
                try:
                    expected = self.dim
                    if expected and expected != actual:
                        logger.error(f"âŒ ë²¡í„° ì°¨ì› ë¶ˆì¼ì¹˜: Qdrant={actual}, Embedder={expected}")
                        logger.error("ğŸ’¡ í•´ê²°: EMBEDDERë¥¼ ì»¬ë ‰ì…˜ ì°¨ì›ê³¼ ì¼ì¹˜(1024=bge-m3, 1536=openai)ì‹œí‚¤ì„¸ìš”.")
                except RuntimeError as e:
                    # ì˜ˆ: bge-m3ì¸ë° sentence-transformers ë¯¸ì„¤ì¹˜
                    logger.warning(f"âš ï¸ ì°¨ì› ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
                except Exception as e:
                    logger.warning(f"âš ï¸ ì°¨ì› ê²€ì¦ ì¤‘ ì˜ˆì™¸: {e}")

        except Exception as e:
            logger.warning(f"âš ï¸ ì»¬ë ‰ì…˜ í™•ì¸ ì‹¤íŒ¨: {e}")
            # ì»¬ë ‰ì…˜ ë¯¸ì¡´ì¬ ì‹œ ìƒì„± (í˜„ì¬ EMBEDDER ê¸°ì¤€ ì°¨ì›)
            try:
                dim = self.dim
                logger.info(f"ğŸ”¨ ì»¬ë ‰ì…˜ ìƒì„± ì‹œì‘: '{self.collection_name}', ì°¨ì›={dim}")
                self.qdrant_client.create_collection(
                    collection_name=self.collection_name,
                    vectors_config=VectorParams(size=dim, distance=Distance.COSINE),
                )
                logger.info(f"âœ… ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ: '{self.collection_name}'")
            except Exception as create_error:
                logger.error(f"âŒ ì»¬ë ‰ì…˜ ìƒì„± ì‹¤íŒ¨: {create_error}")
                # Qdrant ì—°ê²° ì‹¤íŒ¨ ì‹œì—ë„ ì„œë¹„ìŠ¤ê°€ ê³„ì† ì‘ë™í•˜ë„ë¡ í•¨
                pass

    @staticmethod
    def _uuid_from_text_id(text_id: str) -> str:
        return str(uuid5(NAMESPACE_URL, str(text_id)))

    def embed_text(self, text_id: str, text: str, metadata: Optional[Dict[str, Any]] = None):
        try:
            vec = self.encode([text])[0]
            payload = dict(metadata or {})
            payload["text_id"] = str(text_id)
            payload["content"] = text

            point = PointStruct(
                id=self._uuid_from_text_id(text_id),
                vector=vec,
                payload=payload,
            )
            self.qdrant_client.upsert(collection_name=self.collection_name, points=[point], wait=True)
            return {"status": "success", "text_id": text_id}
        except Exception as e:
            return {"status": "error", "message": str(e)}

    def search_similar(self, query: str, limit: int = 5, filters: Optional[Dict[str, Any]] = None):
        try:
            logger.info(f"ğŸ” Qdrant ê²€ìƒ‰ ì‹œì‘: ì¿¼ë¦¬='{query}', ì»¬ë ‰ì…˜='{self.collection_name}', limit={limit}")

            qvec = self.encode([query])[0]
            logger.info(f"ğŸ“Š ì„ë² ë”© ì™„ë£Œ: ë²¡í„° ì°¨ì› = {len(qvec)}")

            qf = None
            if filters:
                qf = Filter(must=[FieldCondition(key=k, match=MatchValue(value=v)) for k, v in filters.items()])
                logger.info(f"ğŸ”§ í•„í„° ì ìš©: {filters}")

            res = self.qdrant_client.search(
                collection_name=self.collection_name,
                query_vector=qvec,
                limit=limit,
                query_filter=qf,
                with_payload=True,
                with_vectors=False,
            )

            logger.info(f"âœ… Qdrant ê²€ìƒ‰ ì™„ë£Œ: {len(res)} ê°œ ê²°ê³¼")
            for i, r in enumerate(res):
                logger.info(
                    f"  {i+1}. Score: {r.score:.3f}, "
                    f"Payload keys: {list(r.payload.keys()) if r.payload else []}"
                )

            return [{"score": r.score, **(r.payload or {})} for r in res]
        except Exception as e:
            logger.error(f"âŒ Qdrant ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return {"status": "error", "message": str(e)}

    def search(self, query: str, limit: int = 5, score_threshold: float = 0.0):
        """ê²€ìƒ‰ ë©”ì„œë“œ (score_threshold ì§€ì›)"""
        try:
            qvec = self.encode([query])[0]
            res = self.qdrant_client.search(
                collection_name=self.collection_name,
                query_vector=qvec,
                limit=limit,
                score_threshold=score_threshold,
                with_payload=True,
                with_vectors=False,
            )
            return [{"score": r.score, **(r.payload or {})} for r in res]
        except Exception as e:
            logger.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def generate_with_context(
        self,
        query: str,
        context_documents: List[Dict[str, Any]],
        system_prompt: str = "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.",
    ):
        try:
            if self._llm is None:
                self._llm = _get_llm()

            parts = []
            for i, doc in enumerate(context_documents, 1):
                title = doc.get("title", "")
                content = doc.get("content", "")
                pages = doc.get("pages", [])
                part = f"[ì°¸ê³  ë¬¸ì„œ {i}]"
                if title:
                    part += f"\nì œëª©: {title}"
                if pages:
                    part += f"\ní˜ì´ì§€: {pages}"
                part += f"\në‚´ìš©:\n{content}\n"
                parts.append(part)
            context = "\n".join(parts)

            from langchain.schema import HumanMessage, SystemMessage
            msgs = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"ì¿¼ë¦¬: {query}\n\nì°¸ê³  ë¬¸ì„œ:\n{context}\n\nìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."),
            ]
            resp = self._llm.invoke(msgs)
            return {"status": "success", "response": resp.content, "context_documents": context_documents}
        except Exception as e:
            return {"status": "error", "message": str(e)}

    def delete_text(self, text_id: str):
        try:
            pid = self._uuid_from_text_id(text_id)
            self.qdrant_client.delete(
                collection_name=self.collection_name,
                points_selector=PointIdsList(points=[pid]),
                wait=True,
            )
            return {"status": "success", "text_id": text_id}
        except Exception as e:
            return {"status": "error", "message": str(e)}

import pandas as pd
import numpy as np
import re
from pathlib import Path

def is_chemical_substance(text):
    """ì‹¤ì œ í™”í•™ë¬¼ì§ˆëª…ì¸ì§€ íŒë‹¨í•©ë‹ˆë‹¤."""
    if pd.isna(text) or text == "":
        return False
    
    text_str = str(text).strip()
    
    # 1. í™”í•™ì‹ íŒ¨í„´ í™•ì¸ (ì˜ˆ: H2O, NaCl, C6H12O6)
    chemical_formula_pattern = r'^[A-Z][a-z]?\d*([A-Z][a-z]?\d*)*$'
    if re.match(chemical_formula_pattern, text_str):
        return True
    
    # 2. ì¼ë°˜ì ì¸ í™”í•™ë¬¼ì§ˆëª… íŒ¨í„´
    # - ìˆ«ì, ë¬¸ì, ê³µë°±, ê´„í˜¸, í•˜ì´í”ˆ, ìŠ¬ë˜ì‹œ í¬í•¨
    # - ìµœì†Œ 2ê¸€ì ì´ìƒ
    # - ë‹¨ìˆœí•œ ê²°ì¸¡ê°’ íŒ¨í„´ì´ ì•„ë‹˜
    if len(text_str) >= 2:
        # ë‹¨ìˆœí•œ ê²°ì¸¡ê°’ íŒ¨í„´ ì œì™¸
        simple_nan_patterns = [
            "nan", "NaN", "NAN", "na", "NA", "n/a", "N/A", 
            "none", "None", "NONE", "unknown", "Unknown", "UNKNOWN",
            "ë¯¸ì…ë ¥", "ì—†ìŒ", "-", "â€”", "â€“", "null", "NULL"
        ]
        
        if text_str.lower() in [p.lower() for p in simple_nan_patterns]:
            return False
        
        # ê´„í˜¸ ì•ˆì— ìˆœë„/ê·œê²© ì •ë³´ê°€ ìˆëŠ” ê²½ìš° (ì˜ˆ: NaN (99%))
        if re.search(r'\([^)]*%[^)]*\)', text_str):
            # ê´„í˜¸ ì œê±° í›„ ë‹¤ì‹œ í™•ì¸
            cleaned = re.sub(r'\([^)]*\)', '', text_str).strip()
            if cleaned.lower() in [p.lower() for p in simple_nan_patterns]:
                return False
        
        # ì‹¤ì œ í™”í•™ë¬¼ì§ˆëª…ìœ¼ë¡œ ë³´ì´ëŠ” íŒ¨í„´
        # - ì•ŒíŒŒë²³ê³¼ ìˆ«ì ì¡°í•©
        # - íŠ¹ìˆ˜ë¬¸ìê°€ ì ì ˆíˆ í¬í•¨
        if re.search(r'[A-Za-z]', text_str):  # ì•ŒíŒŒë²³ í¬í•¨
            return True
    
    return False

def analyze_nan_patterns(data):
    """nan íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
    nan_candidates = []
    chemical_substances = []
    
    for idx, row in data.iterrows():
        raw_name = row['raw_name']
        
        if pd.isna(raw_name) or raw_name == "":
            nan_candidates.append((idx, raw_name, "ë¹ˆ ê°’"))
            continue
        
        text_str = str(raw_name).strip()
        
        # ë‹¨ìˆœí•œ ê²°ì¸¡ê°’ íŒ¨í„´
        simple_nan_patterns = [
            "nan", "NaN", "NAN", "na", "NA", "n/a", "N/A", 
            "none", "None", "NONE", "unknown", "Unknown", "UNKNOWN",
            "ë¯¸ì…ë ¥", "ì—†ìŒ", "-", "â€”", "â€“", "null", "NULL"
        ]
        
        if text_str.lower() in [p.lower() for p in simple_nan_patterns]:
            nan_candidates.append((idx, raw_name, "ë‹¨ìˆœ ê²°ì¸¡ê°’"))
        elif is_chemical_substance(raw_name):
            chemical_substances.append((idx, raw_name, "í™”í•™ë¬¼ì§ˆëª…"))
        else:
            # ì• ë§¤í•œ ì¼€ì´ìŠ¤ - ì¶”ê°€ ë¶„ì„ í•„ìš”
            nan_candidates.append((idx, raw_name, "ì• ë§¤í•œ ì¼€ì´ìŠ¤"))
    
    return nan_candidates, chemical_substances

def prepare_training_data_smart():
    """ìŠ¤ë§ˆíŠ¸í•œ ë°©ë²•ìœ¼ë¡œ í•™ìŠµ ë°ì´í„°ë¥¼ ì¬êµ¬ì„±í•©ë‹ˆë‹¤."""
    
    # 1. ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
    reg_path = Path("data/reg_test1.xlsx")
    pair_path = Path("data/training_pairs_test1_noised_v1.csv")
    
    if not reg_path.exists():
        print("âŒ ê·œì • ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    if not pair_path.exists():
        print("âŒ í›ˆë ¨ ìŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í›ˆë ¨ ìŒ ë°ì´í„° ë¡œë“œ
    pair = pd.read_csv(pair_path).fillna("")
    
    print(f"ğŸ“Š ì›ë³¸ ë°ì´í„°: {len(pair)}ê°œ")
    
    # 2. nan íŒ¨í„´ ë¶„ì„
    print("\nğŸ” nan íŒ¨í„´ ë¶„ì„ ì¤‘...")
    nan_candidates, chemical_substances = analyze_nan_patterns(pair)
    
    print(f"\nğŸ“‹ ë¶„ì„ ê²°ê³¼:")
    print(f"  nan í›„ë³´: {len(nan_candidates)}ê°œ")
    print(f"  í™”í•™ë¬¼ì§ˆëª…: {len(chemical_substances)}ê°œ")
    
    # 3. nan í›„ë³´ë“¤ì˜ ìƒì„¸ ë¶„ì„
    print(f"\nğŸ”¬ nan í›„ë³´ ìƒì„¸ ë¶„ì„:")
    nan_by_type = {}
    for idx, text, reason in nan_candidates:
        if reason not in nan_by_type:
            nan_by_type[reason] = []
        nan_by_type[reason].append((idx, text))
    
    for reason, items in nan_by_type.items():
        print(f"  {reason}: {len(items)}ê°œ")
        if len(items) <= 5:  # 5ê°œ ì´í•˜ë©´ ëª¨ë‘ ì¶œë ¥
            for idx, text in items:
                print(f"    - {text}")
        else:  # 5ê°œ ì´ˆê³¼ë©´ ìƒ˜í”Œë§Œ ì¶œë ¥
            for idx, text in items[:3]:
                print(f"    - {text}")
            print(f"    ... (ì´ {len(items)}ê°œ)")
    
    # 4. ì‚¬ìš©ì í™•ì¸
    print(f"\nâ“ ì²˜ë¦¬ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”:")
    print(f"  1. ëª¨ë“  nan í›„ë³´ë¥¼ UNMAPPEDë¡œ ì²˜ë¦¬")
    print(f"  2. ë‹¨ìˆœ ê²°ì¸¡ê°’ë§Œ UNMAPPEDë¡œ ì²˜ë¦¬")
    print(f"  3. ìˆ˜ë™ìœ¼ë¡œ í™•ì¸ í›„ ì²˜ë¦¬")
    
    # ì„ì‹œë¡œ 2ë²ˆ ì„ íƒ (ë‹¨ìˆœ ê²°ì¸¡ê°’ë§Œ ì²˜ë¦¬)
    choice = 2
    
    if choice == 1:
        # ëª¨ë“  nan í›„ë³´ë¥¼ UNMAPPEDë¡œ ì²˜ë¦¬
        nan_indices = [idx for idx, _, _ in nan_candidates]
        normal_indices = [idx for idx in range(len(pair)) if idx not in nan_indices]
    elif choice == 2:
        # ë‹¨ìˆœ ê²°ì¸¡ê°’ë§Œ UNMAPPEDë¡œ ì²˜ë¦¬
        nan_indices = [idx for idx, _, reason in nan_candidates if reason == "ë‹¨ìˆœ ê²°ì¸¡ê°’"]
        normal_indices = [idx for idx in range(len(pair)) if idx not in nan_indices]
    else:
        # ìˆ˜ë™ í™•ì¸ (ì„ì‹œë¡œ 2ë²ˆê³¼ ë™ì¼í•˜ê²Œ ì²˜ë¦¬)
        nan_indices = [idx for idx, _, reason in nan_candidates if reason == "ë‹¨ìˆœ ê²°ì¸¡ê°’"]
        normal_indices = [idx for idx in range(len(pair)) if idx not in nan_indices]
    
    # 5. ë°ì´í„° ë¶„ë¦¬
    nan_data = pair.iloc[nan_indices]
    normal_data = pair.iloc[normal_indices]
    
    print(f"\nâœ… ìµœì¢… ë¶„ë¥˜:")
    print(f"  ì •ìƒ ë°ì´í„°: {len(normal_data)}ê°œ")
    print(f"  UNMAPPED ë°ì´í„°: {len(nan_data)}ê°œ")
    
    # 6. ë‹¤ìš´ìƒ˜í”Œë§ (í•„ìš”ì‹œ)
    target_nan_ratio = 0.08
    max_nan_count = int(len(normal_data) * target_nan_ratio / (1 - target_nan_ratio))
    
    if len(nan_data) > max_nan_count:
        nan_data = nan_data.sample(n=max_nan_count, random_state=42)
        print(f"  ë‹¤ìš´ìƒ˜í”Œë§ëœ UNMAPPED ë°ì´í„°: {len(nan_data)}ê°œ")
    
    # 7. ìƒˆë¡œìš´ í•™ìŠµ ë°ì´í„° ìƒì„±
    nan_training_data = []
    for _, row in nan_data.iterrows():
        nan_training_data.append({
            'raw_name': row['raw_name'],
            'standard_substance_id': '__UNMAPPED__',
            'standard_substance_name': '__UNMAPPED__',
            'is_unmapped': True
        })
    
    normal_training_data = []
    for _, row in normal_data.iterrows():
        normal_training_data.append({
            'raw_name': row['raw_name'],
            'standard_substance_id': row['standard_substance_id'],
            'standard_substance_name': row['standard_substance_name'],
            'is_unmapped': False
        })
    
    # 8. ë°ì´í„° í•©ì¹˜ê¸°
    new_training_data = pd.DataFrame(normal_training_data + nan_training_data)
    
    print(f"\nğŸ¯ ìµœì¢… í•™ìŠµ ë°ì´í„°:")
    print(f"  ì´ ë°ì´í„°: {len(new_training_data)}ê°œ")
    print(f"  ì •ìƒ ë°ì´í„°: {len(normal_training_data)}ê°œ")
    print(f"  UNMAPPED ë°ì´í„°: {len(nan_training_data)}ê°œ")
    print(f"  UNMAPPED ë¹„ìœ¨: {len(nan_training_data)/len(new_training_data)*100:.1f}%")
    
    # 9. íŒŒì¼ ì €ì¥
    output_path = Path("data/training_pairs_smart_unmapped.csv")
    new_training_data.to_csv(output_path, index=False, encoding='utf-8-sig')
    
    print(f"\nğŸ’¾ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
    
    return new_training_data

if __name__ == "__main__":
    prepare_training_data_smart()


# pip install sentence-transformers faiss-cpu pandas openpyxl
import pandas as pd, numpy as np, faiss, os
from sentence_transformers import SentenceTransformer

REG_XLSX = "./data/reg_test1.xlsx"          # sid,name
PAIR_CSV = "./data/training_pairs_from_reg_hard5_typos3 (1).csv" # raw_name,standard_substance_id (ë…¸ì´ì¦ˆ ë°ì´í„°)
MODEL_DIR = "../../llm_bge-m3"              # ë¡œì»¬ ë² ì´ìŠ¤ ëª¨ë¸ (íŒŒì¸íŠœë‹ ì „)

reg = pd.read_excel(REG_XLSX).fillna("")
reg = reg.rename(columns=lambda c: str(c).strip().lower())
reg = reg[["sid","name"]].dropna().drop_duplicates()

pair = pd.read_csv(PAIR_CSV).fillna("")
pair = pair.rename(columns=lambda c: str(c).strip().lower())

# NaN ê°’ ì œê±° - ì‹¤ì œ ë§¤í•‘ ê°€ëŠ¥í•œ ë°ì´í„°ë§Œ ì‚¬ìš©
pair = pair[["raw_name","standard_substance_id"]].dropna()
print(f"ðŸ“Š ì›ë³¸ ë°ì´í„°: {len(pair)}ê°œ")
print(f"ðŸ“Š NaN ì œê±° í›„: {len(pair)}ê°œ")

# ì¶”ê°€ í•„í„°ë§: ë¹ˆ ë¬¸ìžì—´ì´ë‚˜ ì˜ë¯¸ì—†ëŠ” ê°’ ì œê±°
pair = pair[pair["raw_name"].str.strip() != ""]
pair = pair[pair["standard_substance_id"].str.strip() != ""]
print(f"ðŸ“Š ìµœì¢… í‰ê°€ ë°ì´í„°: {len(pair)}ê°œ")

model = SentenceTransformer(MODEL_DIR)

def enc_passage(texts):  # passage prefix ê¶Œìž¥
    return model.encode([f"passage: {t}" for t in texts], normalize_embeddings=True,
                        batch_size=32, show_progress_bar=True).astype("float32")
def enc_query(texts):
    return model.encode([f"query: {t}" for t in texts], normalize_embeddings=True,
                        batch_size=32, show_progress_bar=True).astype("float32")

# 1) ì¸ë±ìŠ¤ êµ¬ì¶•
print(f"ðŸ”„ í‘œì¤€ í•„ë“œ ìž„ë² ë”© ìƒì„± ì¤‘... ({len(reg)}ê°œ)")
p_texts = reg["name"].astype(str).tolist()
p_vecs = enc_passage(p_texts)
print(f"âœ… í‘œì¤€ í•„ë“œ ìž„ë² ë”© ì™„ë£Œ: {p_vecs.shape}")

print("ðŸ”„ FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ì¤‘...")
index = faiss.IndexFlatIP(p_vecs.shape[1])
index.add(p_vecs)
p_sids = reg["sid"].tolist()
print("âœ… FAISS ì¸ë±ìŠ¤ êµ¬ì¶• ì™„ë£Œ")

# 2) í‰ê°€ (Recall@1/5, ì ìˆ˜/ë§ˆì§„ â†’ ì‹ ë¢°ë„)
print(f"ðŸ”„ ì¿¼ë¦¬ ìž„ë² ë”© ìƒì„± ì¤‘... ({len(pair)}ê°œ)")
q_texts = pair["raw_name"].astype(str).tolist()
q_vecs = enc_query(q_texts)
print(f"âœ… ì¿¼ë¦¬ ìž„ë² ë”© ì™„ë£Œ: {q_vecs.shape}")

print("ðŸ”„ FAISS ê²€ìƒ‰ ë° í‰ê°€ ì¤‘...")
scores, idxs = index.search(q_vecs, 5)
print("âœ… FAISS ê²€ìƒ‰ ì™„ë£Œ")

gold = pair["standard_substance_id"].tolist()
hit1 = hit5 = 0
rows = []
for i, (sc, ix) in enumerate(zip(scores, idxs)):
    cands = [p_sids[j] for j in ix]
    top1_sid, top1 = cands[0], float(sc[0])
    top2 = float(sc[1]) if len(sc) > 1 else 0.0
    margin = max(top1 - top2, 0.0)
    # ê°„ë‹¨ ì‹ ë¢°ë„(ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì „): ê°€ì¤‘í•©
    conf = 0.75 * top1 + 0.25 * margin
    band = "mapped" if conf >= 0.80 else ("needs_review" if conf >= 0.50 else "not_mapped")
    is1 = (top1_sid == gold[i]); hit1 += int(is1)
    is5 = int(gold[i] in cands); hit5 += is5
    rows.append({
        "raw_name": q_texts[i],
        "gold_sid": gold[i],
        "pred_sid": top1_sid,
        "score_top1": top1,
        "margin": margin,
        "confidence": conf,
        "band": band,
        "top5_sids": cands,
        "top5_scores": [float(s) for s in sc]
    })

print(f"Recall@1 = {hit1/len(gold):.3f} | Recall@5 = {hit5/len(gold):.3f}")

# 3) ê²°ê³¼ ì €ìž¥
out = pd.DataFrame(rows)
out.to_csv("./data/retrieval_eval_results.csv", index=False, encoding="utf-8-sig")
print("saved: ./data/retrieval_eval_results.csv")

import pandas as pd
import numpy as np
import json
from pathlib import Path

def debug_nan_issue():
    """JSONL ë³€í™˜ ê³¼ì •ì—ì„œ nanì´ ì–´ë–»ê²Œ ìƒì„±ë˜ì—ˆëŠ”ì§€ ë””ë²„ê¹…í•©ë‹ˆë‹¤."""
    
    # 1. ì›ë³¸ CSV íŒŒì¼ í™•ì¸
    csv_path = Path("data/training_pairs_test1_noised_v1.csv")
    
    if not csv_path.exists():
        print("âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("ğŸ” ì›ë³¸ CSV íŒŒì¼ ë¶„ì„...")
    
    # CSV íŒŒì¼ì„ ë‹¤ì–‘í•œ ë°©ë²•ìœ¼ë¡œ ë¡œë“œí•´ì„œ ë¹„êµ
    print("\n1. ê¸°ë³¸ ë¡œë“œ:")
    df1 = pd.read_csv(csv_path)
    print(f"   ë°ì´í„° íƒ€ì…: {df1.dtypes}")
    print(f"   ë¹ˆ ê°’ ê°œìˆ˜: {df1.isnull().sum()}")
    
    print("\n2. fillna('') ì—†ì´ ë¡œë“œ:")
    df2 = pd.read_csv(csv_path, keep_default_na=True)
    print(f"   ë°ì´í„° íƒ€ì…: {df2.dtypes}")
    print(f"   ë¹ˆ ê°’ ê°œìˆ˜: {df2.isnull().sum()}")
    
    print("\n3. fillna('') ì ìš©:")
    df3 = pd.read_csv(csv_path).fillna("")
    print(f"   ë°ì´í„° íƒ€ì…: {df3.dtypes}")
    print(f"   ë¹ˆ ê°’ ê°œìˆ˜: {df3.isnull().sum()}")
    
    # 4. raw_name ì»¬ëŸ¼ ìƒì„¸ ë¶„ì„
    print(f"\nğŸ”¬ raw_name ì»¬ëŸ¼ ìƒì„¸ ë¶„ì„:")
    
    # ì›ë³¸ ë°ì´í„°ì—ì„œ raw_name í™•ì¸
    raw_names = df1['raw_name'].dropna()
    print(f"  ì›ë³¸ raw_name ê°œìˆ˜: {len(raw_names)}")
    
    # ê³ ìœ ê°’ í™•ì¸
    unique_values = raw_names.unique()
    print(f"  ê³ ìœ ê°’ ê°œìˆ˜: {len(unique_values)}")
    
    # "nan" ê´€ë ¨ ê°’ë“¤ í™•ì¸
    nan_like_values = [val for val in unique_values if str(val).lower() in ['nan', 'na', 'n/a', 'none', 'null']]
    print(f"  nan ê´€ë ¨ ê³ ìœ ê°’: {nan_like_values}")
    
    # 5. ì‹¤ì œ "nan" ë¬¸ìì—´ ê°œìˆ˜ í™•ì¸
    actual_nan_count = (raw_names == "nan").sum()
    print(f"  ì‹¤ì œ 'nan' ë¬¸ìì—´ ê°œìˆ˜: {actual_nan_count}")
    
    # 6. numpy.nan ê°œìˆ˜ í™•ì¸
    numpy_nan_count = raw_names.isna().sum()
    print(f"  numpy.nan ê°œìˆ˜: {numpy_nan_count}")
    
    # 7. fillna ì ìš© í›„ í™•ì¸
    filled_names = df1['raw_name'].fillna("")
    filled_nan_count = (filled_names == "nan").sum()
    print(f"  fillna í›„ 'nan' ë¬¸ìì—´ ê°œìˆ˜: {filled_nan_count}")
    
    # 8. ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
    print(f"\nğŸ“‹ ìƒ˜í”Œ ë°ì´í„°:")
    print("ì›ë³¸ ë°ì´í„° (ì²˜ìŒ 10ê°œ):")
    print(df1['raw_name'].head(10))
    
    print("\nfillna ì ìš© í›„ (ì²˜ìŒ 10ê°œ):")
    print(df1['raw_name'].fillna("").head(10))
    
    # 9. JSONL ë³€í™˜ ì‹œë®¬ë ˆì´ì…˜
    print(f"\nğŸ”„ JSONL ë³€í™˜ ì‹œë®¬ë ˆì´ì…˜:")
    
    # ì›ë³¸ ë°ì´í„°ë¡œ JSONL ë³€í™˜
    jsonl_data_original = []
    for _, row in df1.iterrows():
        jsonl_data_original.append({
            'raw_name': row['raw_name'],
            'standard_substance_id': row['standard_substance_id'],
            'standard_substance_name': row['standard_substance_name']
        })
    
    # fillna ì ìš© í›„ JSONL ë³€í™˜
    jsonl_data_filled = []
    for _, row in df1.iterrows():
        jsonl_data_filled.append({
            'raw_name': row['raw_name'] if pd.notna(row['raw_name']) else "",
            'standard_substance_id': row['standard_substance_id'] if pd.notna(row['standard_substance_id']) else "",
            'standard_substance_name': row['standard_substance_name'] if pd.notna(row['standard_substance_name']) else ""
        })
    
    # nan ê°œìˆ˜ ë¹„êµ
    original_nan_count = sum(1 for item in jsonl_data_original if str(item['raw_name']).lower() == 'nan')
    filled_nan_count = sum(1 for item in jsonl_data_filled if str(item['raw_name']).lower() == 'nan')
    
    print(f"  ì›ë³¸ JSONL ë³€í™˜ í›„ 'nan' ê°œìˆ˜: {original_nan_count}")
    print(f"  fillna ì ìš© í›„ JSONL ë³€í™˜ 'nan' ê°œìˆ˜: {filled_nan_count}")
    
    # 10. í•´ê²° ë°©ì•ˆ ì œì‹œ
    print(f"\nğŸ’¡ í•´ê²° ë°©ì•ˆ:")
    
    if original_nan_count > 0:
        print(f"  1. ì›ë³¸ ë°ì´í„°ì— ì‹¤ì œ 'nan' ë¬¸ìì—´ì´ {original_nan_count}ê°œ ìˆìŠµë‹ˆë‹¤.")
        print(f"  2. ì´ëŠ” ë°ì´í„° ìˆ˜ì§‘ ê³¼ì •ì—ì„œ ë°œìƒí•œ ê²ƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    if numpy_nan_count > 0:
        print(f"  3. numpy.nanì´ {numpy_nan_count}ê°œ ìˆìŠµë‹ˆë‹¤.")
        print(f"  4. fillna() ì²˜ë¦¬ ì‹œ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.")
    
    print(f"  5. ê¶Œì¥ì‚¬í•­: ì›ë³¸ ë°ì´í„°ì—ì„œ ì‹¤ì œ ê²°ì¸¡ê°’ì„ í™•ì¸í•˜ê³  ì ì ˆíˆ ì²˜ë¦¬í•˜ì„¸ìš”.")
    
    return df1

def fix_training_data():
    """í•™ìŠµ ë°ì´í„°ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤."""
    
    print("\nğŸ”§ í•™ìŠµ ë°ì´í„° ìˆ˜ì •...")
    
    # ì›ë³¸ ë°ì´í„° ë¡œë“œ
    csv_path = Path("data/training_pairs_test1_noised_v1.csv")
    df = pd.read_csv(csv_path)
    
    # ì‹¤ì œ ê²°ì¸¡ê°’ë§Œ ì²˜ë¦¬ (numpy.nan)
    df_fixed = df.copy()
    df_fixed['raw_name'] = df_fixed['raw_name'].fillna("")
    df_fixed['standard_substance_id'] = df_fixed['standard_substance_id'].fillna("")
    df_fixed['standard_substance_name'] = df_fixed['standard_substance_name'].fillna("")
    
    # ë¹ˆ ë¬¸ìì—´ì„ ê°€ì§„ ë°ì´í„° í™•ì¸
    empty_raw_names = df_fixed[df_fixed['raw_name'] == ""]
    print(f"  ë¹ˆ raw_name ê°œìˆ˜: {len(empty_raw_names)}")
    
    # ì‹¤ì œ "nan" ë¬¸ìì—´ì„ ê°€ì§„ ë°ì´í„° í™•ì¸
    actual_nan_names = df_fixed[df_fixed['raw_name'] == "nan"]
    print(f"  ì‹¤ì œ 'nan' ë¬¸ìì—´ ê°œìˆ˜: {len(actual_nan_names)}")
    
    # ìˆ˜ì •ëœ ë°ì´í„° ì €ì¥
    output_path = Path("data/training_pairs_fixed.csv")
    df_fixed.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"  ìˆ˜ì •ëœ ë°ì´í„° ì €ì¥: {output_path}")
    
    return df_fixed

if __name__ == "__main__":
    debug_nan_issue()
    fix_training_data()


#!/usr/bin/env python3
"""
ìš´ì˜ ì§€í‘œ ì¤‘ì‹¬ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
Precision(mapped) â‰¥ 0.97 ì¡°ê±´ì—ì„œ Coverage ìµœëŒ€í™”
"""

import pandas as pd
import numpy as np
import faiss
import torch
from sentence_transformers import SentenceTransformer
from pathlib import Path
import time
from typing import List, Dict, Tuple

# GPU ì„¤ì •
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ðŸš€ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

# íŒŒì¼ ê²½ë¡œ ì„¤ì •
REG_XLSX = Path("data/reg_test1.xlsx")
PAIR_CSV = Path("data/training_pairs_from_reg_hard5_typos3 (1).csv")
MODEL_DIR = "model/bomi-ai"  # BOMI AI ëª¨ë¸ ê²½ë¡œ

def load_data():
    """ë°ì´í„° ë¡œë“œ"""
    print("ðŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    # ê·œì • ë°ì´í„°
    reg = pd.read_excel(REG_XLSX).fillna("")
    reg.columns = [c.strip().lower() for c in reg.columns]
    reg = reg[["sid", "name"]].drop_duplicates()
    
    # í›ˆë ¨ ìŒ ë°ì´í„°
    pair = pd.read_csv(PAIR_CSV).fillna("")
    pair.columns = [c.strip().lower() for c in pair.columns]
    pair = pair[["raw_name", "standard_substance_id"]].drop_duplicates()
    
    return reg, pair

def load_model():
    """ëª¨ë¸ ë¡œë“œ"""
    print(f"ðŸ¤– ëª¨ë¸ ë¡œë“œ ì¤‘: {MODEL_DIR}")
    model = SentenceTransformer(MODEL_DIR, device=device)
    return model

def encode_texts(model, texts: List[str], prefix: str, batch_size: int = 512):
    """í…ìŠ¤íŠ¸ ì¸ì½”ë”©"""
    encoded_texts = [f"{prefix}: {text}" for text in texts]
    embeddings = model.encode(
        encoded_texts, 
        normalize_embeddings=True, 
        batch_size=batch_size, 
        show_progress_bar=True
    ).astype("float32")
    return embeddings

def calculate_confidence(top1_score: float, margin: float) -> float:
    """ì‹ ë¢°ë„ ê³„ì‚°: 0.75*top1 + 0.25*margin"""
    return 0.75 * top1_score + 0.25 * max(margin, 0.0)

def evaluate_with_threshold(results_df: pd.DataFrame, confidence_threshold: float) -> Dict:
    """íŠ¹ì • ì‹ ë¢°ë„ ìž„ê³„ê°’ì—ì„œ ì„±ëŠ¥ í‰ê°€"""
    # ì‹ ë¢°ë„ ë°´ë“œ ê²°ì •
    mapped_mask = results_df['confidence'] >= confidence_threshold
    mapped_df = results_df[mapped_mask]
    
    if len(mapped_df) == 0:
        return {
            'threshold': confidence_threshold,
            'precision': 0.0,
            'coverage': 0.0,
            'mapped_count': 0,
            'total_count': len(results_df)
        }
    
    # Precision ê³„ì‚°
    correct_mapped = (mapped_df['gold_sid'] == mapped_df['pred_sid']).sum()
    precision = correct_mapped / len(mapped_df)
    
    # Coverage ê³„ì‚°
    coverage = len(mapped_df) / len(results_df)
    
    return {
        'threshold': confidence_threshold,
        'precision': precision,
        'coverage': coverage,
        'mapped_count': len(mapped_df),
        'total_count': len(results_df),
        'correct_mapped': correct_mapped
    }

def find_optimal_threshold(results_df: pd.DataFrame, min_precision: float = 0.97) -> Dict:
    """Precision â‰¥ 0.97 ì¡°ê±´ì—ì„œ Coverage ìµœëŒ€í™”í•˜ëŠ” ìž„ê³„ê°’ ì°¾ê¸°"""
    print(f"ðŸ” ìµœì  ìž„ê³„ê°’ íƒìƒ‰ ì¤‘ (ìµœì†Œ Precision: {min_precision})...")
    
    # ì‹ ë¢°ë„ ë²”ìœ„ì—ì„œ ê·¸ë¦¬ë“œ ìŠ¤ìœ•
    thresholds = np.arange(0.3, 0.95, 0.01)
    results = []
    
    for threshold in thresholds:
        result = evaluate_with_threshold(results_df, threshold)
        results.append(result)
    
    results_df = pd.DataFrame(results)
    
    # Precision â‰¥ 0.97 ì¡°ê±´ ë§Œì¡±í•˜ëŠ” ê²ƒë“¤ ì¤‘ Coverage ìµœëŒ€
    valid_results = results_df[results_df['precision'] >= min_precision]
    
    if len(valid_results) == 0:
        print(f"âš ï¸ Precision {min_precision} ì´ìƒì¸ ìž„ê³„ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
        # ê°€ìž¥ ë†’ì€ Precision ì°¾ê¸°
        best_idx = results_df['precision'].idxmax()
        best_result = results_df.loc[best_idx]
        print(f"ìµœê³  Precision: {best_result['precision']:.3f} (ìž„ê³„ê°’: {best_result['threshold']:.2f})")
        return best_result.to_dict()
    
    # Coverage ìµœëŒ€í™”
    best_idx = valid_results['coverage'].idxmax()
    best_result = valid_results.loc[best_idx]
    
    print(f"âœ… ìµœì  ìž„ê³„ê°’: {best_result['threshold']:.2f}")
    print(f"  Precision: {best_result['precision']:.3f}")
    print(f"  Coverage: {best_result['coverage']:.3f}")
    
    return best_result.to_dict()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("ìš´ì˜ ì§€í‘œ ì¤‘ì‹¬ í‰ê°€")
    print("=" * 60)
    
    # 1. ë°ì´í„° ë¡œë“œ
    reg, pair = load_data()
    print(f"âœ… ê·œì • ë°ì´í„°: {len(reg)}ê°œ")
    print(f"âœ… í›ˆë ¨ ìŒ ë°ì´í„°: {len(pair)}ê°œ")
    
    # 2. ëª¨ë¸ ë¡œë“œ
    model = load_model()
    
    # 3. í…ìŠ¤íŠ¸ ì¸ì½”ë”©
    print("\nðŸ”„ í…ìŠ¤íŠ¸ ì¸ì½”ë”© ì¤‘...")
    passage_embeddings = encode_texts(model, reg["name"].tolist(), "passage")
    query_embeddings = encode_texts(model, pair["raw_name"].tolist(), "query")
    
    # 4. FAISS ì¸ë±ìŠ¤ ìƒì„±
    print("\nðŸ” FAISS ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
    index = faiss.IndexFlatIP(passage_embeddings.shape[1])
    index.add(passage_embeddings)
    
    # 5. ê²€ìƒ‰ ë° í‰ê°€
    print("\nðŸ“ˆ ê²€ìƒ‰ ë° í‰ê°€ ì¤‘...")
    scores, idxs = index.search(query_embeddings, 5)
    
    # 6. ê²°ê³¼ ë¶„ì„
    rows = []
    for i, (sc, ix) in enumerate(zip(scores, idxs)):
        cands = [reg["sid"].iloc[j] for j in ix]
        top1_score = float(sc[0])
        top2_score = float(sc[1]) if len(sc) > 1 else 0.0
        margin = max(top1_score - top2_score, 0.0)
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        confidence = calculate_confidence(top1_score, margin)
        
        rows.append({
            "raw_name": pair["raw_name"].iloc[i],
            "gold_sid": pair["standard_substance_id"].iloc[i],
            "pred_sid": cands[0],
            "score_top1": top1_score,
            "margin": margin,
            "confidence": confidence,
            "top5_sids": cands,
            "top5_scores": [float(s) for s in sc]
        })
    
    results_df = pd.DataFrame(rows)
    
    # 7. ìµœì  ìž„ê³„ê°’ ì°¾ê¸°
    optimal_result = find_optimal_threshold(results_df, min_precision=0.97)
    
    # 8. ìƒì„¸ ë¶„ì„
    print("\nðŸ“Š ìƒì„¸ ë¶„ì„ ê²°ê³¼:")
    print(f"  ìµœì  ì‹ ë¢°ë„ ìž„ê³„ê°’: {optimal_result['threshold']:.2f}")
    print(f"  Precision: {optimal_result['precision']:.3f}")
    print(f"  Coverage: {optimal_result['coverage']:.3f}")
    print(f"  ìžë™ ë§¤í•‘ ê°œìˆ˜: {optimal_result['mapped_count']}/{optimal_result['total_count']}")
    
    # 9. ì‹ ë¢°ë„ ë¶„í¬
    print("\nðŸŽ¯ ì‹ ë¢°ë„ ë¶„í¬:")
    confidence_ranges = [
        (0.0, 0.5, "ë‚®ìŒ"),
        (0.5, 0.7, "ë³´í†µ"),
        (0.7, 0.9, "ë†’ìŒ"),
        (0.9, 1.0, "ë§¤ìš° ë†’ìŒ")
    ]
    
    for low, high, label in confidence_ranges:
        count = len(results_df[(results_df['confidence'] >= low) & (results_df['confidence'] < high)])
        percentage = count / len(results_df) * 100
        print(f"  {label} ({low:.1f}-{high:.1f}): {count}ê°œ ({percentage:.1f}%)")
    
    # 10. ê²°ê³¼ ì €ìž¥
    output_file = "operational_evaluation_results.csv"
    results_df.to_csv(output_file, index=False, encoding="utf-8-sig")
    print(f"\nðŸ’¾ ê²°ê³¼ ì €ìž¥ ì™„ë£Œ: {output_file}")
    
    # 11. ìµœì¢… ìš”ì•½
    print("\n" + "=" * 60)
    print("ðŸŽ‰ ìš´ì˜ ì§€í‘œ í‰ê°€ ì™„ë£Œ!")
    print("=" * 60)
    print(f"ðŸ“ˆ ìµœì  ìš´ì˜ ì„¤ì •:")
    print(f"  ì‹ ë¢°ë„ ìž„ê³„ê°’: {optimal_result['threshold']:.2f}")
    print(f"  ì˜ˆìƒ Precision: {optimal_result['precision']:.3f}")
    print(f"  ì˜ˆìƒ Coverage: {optimal_result['coverage']:.3f}")
    print(f"  ìžë™ ë§¤í•‘ ë¹„ìœ¨: {optimal_result['coverage']*100:.1f}%")

if __name__ == "__main__":
    main()

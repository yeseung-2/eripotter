#!/usr/bin/env python3
"""
Fine-tuned BGE-M3 ëª¨ë¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
GPU ìµœì í™” ë° ì„±ëŠ¥ í‰ê°€
"""

import pandas as pd
import numpy as np
import faiss
import torch
from sentence_transformers import SentenceTransformer
from pathlib import Path
import time
import os
from typing import List, Dict, Tuple

# GPU ì„¤ì •
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸš€ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB")

# íŒŒì¼ ê²½ë¡œ ì„¤ì • (monitoring-train ì„œë¹„ìŠ¤ ë‚´ë¶€)
REG_XLSX = Path("data/reg_test1.xlsx")
PAIR_CSV = Path("data/training_pairs_from_reg_hard5_typos3 (1).csv")
MODEL_DIR = "model/bomi-ai"  # BOMI AI ëª¨ë¸ ê²½ë¡œ

def check_files():
    """í•„ìš”í•œ íŒŒì¼ë“¤ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
    print("ğŸ” íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸...")
    
    files_to_check = [
        ("ê·œì • ë°ì´í„° (Excel)", REG_XLSX),
        ("í›ˆë ¨ ìŒ ë°ì´í„° (CSV)", PAIR_CSV),
        ("Fine-tuned ëª¨ë¸", MODEL_DIR)
    ]
    
    all_exist = True
    for name, path in files_to_check:
        exists = os.path.exists(path)
        status = "âœ…" if exists else "âŒ"
        print(f"  {status} {name}: {path}")
        if not exists:
            all_exist = False
    
    if not all_exist:
        print("\nâš ï¸ ì¼ë¶€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return False
    
    print("âœ… ëª¨ë“  íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤.")
    return True

def load_data():
    """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    print("\nğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    # ê·œì • ë°ì´í„° ë¡œë“œ
    print("  ê·œì • ë°ì´í„° ë¡œë“œ...")
    reg = pd.read_excel(REG_XLSX).fillna("")
    reg.columns = [c.strip().lower() for c in reg.columns]
    reg = reg[["sid", "name"]].drop_duplicates()
    print(f"    ê·œì • ë°ì´í„°: {len(reg)}ê°œ í•­ëª©")
    
    # í›ˆë ¨ ìŒ ë°ì´í„° ë¡œë“œ
    print("  í›ˆë ¨ ìŒ ë°ì´í„° ë¡œë“œ...")
    pair = pd.read_csv(PAIR_CSV).fillna("")
    pair.columns = [c.strip().lower() for c in pair.columns]
    pair = pair[["raw_name", "standard_substance_id"]].drop_duplicates()
    print(f"    í›ˆë ¨ ìŒ ë°ì´í„°: {len(pair)}ê°œ í•­ëª©")
    
    return reg, pair

def load_model():
    """ëª¨ë¸ ë¡œë“œ"""
    print(f"\nğŸ¤– ëª¨ë¸ ë¡œë“œ ì¤‘: {MODEL_DIR}")
    
    try:
        model = SentenceTransformer(MODEL_DIR, device=device)
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ (ë””ë°”ì´ìŠ¤: {device})")
        return model
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def encode_texts(model, texts: List[str], prefix: str, batch_size: int = None):
    """í…ìŠ¤íŠ¸ ì¸ì½”ë”© (GPU ìµœì í™”)"""
    if batch_size is None:
        batch_size = 512 if torch.cuda.is_available() else 256
    
    print(f"  ì¸ì½”ë”© ì¤‘... (ë°°ì¹˜ í¬ê¸°: {batch_size})")
    start_time = time.time()
    
    encoded_texts = [f"{prefix}: {text}" for text in texts]
    embeddings = model.encode(
        encoded_texts, 
        normalize_embeddings=True, 
        batch_size=batch_size, 
        show_progress_bar=True,
        convert_to_numpy=True
    ).astype("float32")
    
    elapsed_time = time.time() - start_time
    print(f"  ì¸ì½”ë”© ì™„ë£Œ: {len(texts)}ê°œ í…ìŠ¤íŠ¸, {elapsed_time:.2f}ì´ˆ")
    
    return embeddings

def build_index(passage_embeddings):
    """FAISS ì¸ë±ìŠ¤ ìƒì„±"""
    print("\nğŸ” FAISS ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
    
    dimension = passage_embeddings.shape[1]
    index = faiss.IndexFlatIP(dimension)
    index.add(passage_embeddings)
    
    print(f"âœ… ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ (ì°¨ì›: {dimension})")
    return index

def evaluate_model(index, query_embeddings, passage_sids: List[str], 
                  raw_names: List[str], gold_sids: List[str], top_k: int = 5):
    """ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
    print(f"\nğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì¤‘... (Top-{top_k})")
    
    start_time = time.time()
    scores, idxs = index.search(query_embeddings, top_k)
    elapsed_time = time.time() - start_time
    
    print(f"  ê²€ìƒ‰ ì™„ë£Œ: {elapsed_time:.2f}ì´ˆ")
    
    # ì„±ëŠ¥ ê³„ì‚°
    hit1 = hit5 = 0
    rows = []
    
    for i, (sc, ix) in enumerate(zip(scores, idxs)):
        cands = [passage_sids[j] for j in ix]
        top1, top2 = float(sc[0]), float(sc[1]) if len(sc) > 1 else 0.0
        margin = max(top1 - top2, 0.0)
        
        # ì‹ ë¢°ë„ ê³„ì‚° ë°©ì‹ ê°œì„ 
        # top1 ì ìˆ˜ì— ë” ë†’ì€ ê°€ì¤‘ì¹˜, marginì— ë‚®ì€ ê°€ì¤‘ì¹˜
        conf = 0.85 * top1 + 0.15 * margin
        
        # ì‹ ë¢°ë„ ë°´ë“œ ê²°ì • (ì›ë˜ ì„ê³„ê°’ ìœ ì§€)
        if conf >= 0.70:
            band = "mapped"
        elif conf >= 0.40:
            band = "needs_review"
        else:
            band = "not_mapped"
        
        # ì •í™•ë„ ê³„ì‚°
        hit1 += int(cands[0] == gold_sids[i])
        hit5 += int(gold_sids[i] in cands)
        
        # ê²°ê³¼ ì €ì¥
        rows.append({
            "raw_name": raw_names[i],
            "gold_sid": gold_sids[i],
            "pred_sid": cands[0],
            "score_top1": top1,
            "margin": margin,
            "confidence": conf,
            "band": band,
            "top5_sids": cands,
            "top5_scores": [float(s) for s in sc]
        })
    
    return hit1, hit5, len(gold_sids), rows

def save_results(results_df, hit1, hit5, total):
    """ê²°ê³¼ ì €ì¥"""
    print("\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
    
    # ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥
    recall1 = hit1 / total
    recall5 = hit5 / total
    
    print(f"ğŸ“Š ì„±ëŠ¥ ê²°ê³¼:")
    print(f"  Recall@1: {recall1:.3f} ({hit1}/{total})")
    print(f"  Recall@5: {recall5:.3f} ({hit5}/{total})")
    
    # ì‹ ë¢°ë„ ë°´ë“œë³„ ë¶„í¬ ë° ì •í™•ë„
    band_counts = results_df['band'].value_counts()
    print(f"\nğŸ¯ ì‹ ë¢°ë„ ë°´ë“œë³„ ë¶„í¬:")
    for band, count in band_counts.items():
        percentage = count / len(results_df) * 100
        print(f"  {band}: {count}ê°œ ({percentage:.1f}%)")
    
    # Mapped ì¼€ì´ìŠ¤ì˜ Precision ê³„ì‚°
    mapped_df = results_df[results_df['band'] == 'mapped']
    if len(mapped_df) > 0:
        mapped_correct = (mapped_df['gold_sid'] == mapped_df['pred_sid']).sum()
        mapped_precision = mapped_correct / len(mapped_df)
        print(f"\nğŸ¯ Mapped ì¼€ì´ìŠ¤ ì •í™•ë„ (Precision):")
        print(f"  Precision: {mapped_precision:.3f} ({mapped_correct}/{len(mapped_df)})")
        
        # Needs_review ì¼€ì´ìŠ¤ì˜ ì •í™•ë„ë„ ê³„ì‚°
        review_df = results_df[results_df['band'] == 'needs_review']
        if len(review_df) > 0:
            review_correct = (review_df['gold_sid'] == review_df['pred_sid']).sum()
            review_precision = review_correct / len(review_df)
            print(f"  Needs_review ì •í™•ë„: {review_precision:.3f} ({review_correct}/{len(review_df)})")
    
    # ê²°ê³¼ ì €ì¥
    output_file = "finetuned_retrieval_eval.csv"
    results_df.to_csv(output_file, index=False, encoding="utf-8-sig")
    print(f"âœ… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_file}")
    
    return recall1, recall5

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("Fine-tuned BGE-M3 ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # 1. íŒŒì¼ í™•ì¸
    if not check_files():
        return
    
    # 2. ë°ì´í„° ë¡œë“œ
    reg, pair = load_data()
    
    # 3. ëª¨ë¸ ë¡œë“œ
    model = load_model()
    if model is None:
        return
    
    # 4. í…ìŠ¤íŠ¸ ì¸ì½”ë”©
    print("\nğŸ”„ í…ìŠ¤íŠ¸ ì¸ì½”ë”© ì¤‘...")
    
    # Passage ì¸ì½”ë”©
    passage_embeddings = encode_texts(model, reg["name"].tolist(), "passage")
    
    # Query ì¸ì½”ë”©
    query_embeddings = encode_texts(model, pair["raw_name"].tolist(), "query")
    
    # 5. FAISS ì¸ë±ìŠ¤ ìƒì„±
    index = build_index(passage_embeddings)
    
    # 6. ëª¨ë¸ í‰ê°€
    hit1, hit5, total, rows = evaluate_model(
        index, 
        query_embeddings, 
        reg["sid"].tolist(),
        pair["raw_name"].tolist(),
        pair["standard_substance_id"].tolist()
    )
    
    # 7. ê²°ê³¼ ì €ì¥
    results_df = pd.DataFrame(rows)
    recall1, recall5 = save_results(results_df, hit1, hit5, total)
    
    # 8. ìµœì¢… ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 60)
    print(f"ğŸ“Š ìµœì¢… ì„±ëŠ¥:")
    print(f"  Recall@1: {recall1:.3f}")
    print(f"  Recall@5: {recall5:.3f}")
    print(f"  ì´ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {total}ê°œ")
    
    if torch.cuda.is_available():
        print(f"\nğŸš€ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:")
        print(f"  í• ë‹¹ë¨: {torch.cuda.memory_allocated() / 1024**3:.2f}GB")
        print(f"  ìºì‹œë¨: {torch.cuda.memory_reserved() / 1024**3:.2f}GB")

if __name__ == "__main__":
    main()

"""
ë°ì´í„° ë§¤í•‘ í•™ìŠµ ëª¨ë“ˆ
BGE-M3 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í•„ë“œ ë§¤í•‘ í•™ìŠµ
"""

import os
import json
import numpy as np
import pandas as pd
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import torch

class FieldMappingTrainer:
    """í•„ë“œ ë§¤í•‘ í•™ìŠµê¸°"""
    
    def __init__(self, model_path: str = "./bge-m3"):
        """
        Args:
            model_path: BGE-M3 ëª¨ë¸ ê²½ë¡œ
        """
        self.model_path = model_path
        self.model = None
        self.standard_fields = []
        self.standard_embeddings = None
        
    def load_model(self):
        """BGE-M3 ëª¨ë¸ ë¡œë“œ"""
        try:
            print(f"ğŸ”„ BGE-M3 ëª¨ë¸ ë¡œë”© ì¤‘: {self.model_path}")
            self.model = SentenceTransformer(self.model_path)
            print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            raise
    
    def load_training_data(self, training_data_path: str):
        """
        í•™ìŠµ ë°ì´í„° ë¡œë“œ (ì •ë‹µìŒ)
        
        Args:
            training_data_path: í•™ìŠµ ë°ì´í„° JSON íŒŒì¼ ê²½ë¡œ
        """
        try:
            with open(training_data_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # í‘œì¤€ í•„ë“œë“¤ ì¶”ì¶œ
            self.standard_fields = []
            for item in data:
                if 'standard_field' in item:
                    self.standard_fields.append(item['standard_field'])
            
            print(f"âœ… í•™ìŠµ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.standard_fields)}ê°œ í‘œì¤€ í•„ë“œ")
            return data
            
        except Exception as e:
            print(f"âŒ í•™ìŠµ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def create_standard_embeddings(self):
        """í‘œì¤€ í•„ë“œë“¤ì˜ ì„ë² ë”© ìƒì„±"""
        if not self.model:
            self.load_model()
        
        if not self.standard_fields:
            raise ValueError("í‘œì¤€ í•„ë“œê°€ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµ ë°ì´í„°ë¥¼ ë¨¼ì € ë¡œë“œí•˜ì„¸ìš”.")
        
        print("ğŸ”„ í‘œì¤€ í•„ë“œ ì„ë² ë”© ìƒì„± ì¤‘...")
        self.standard_embeddings = self.model.encode(
            self.standard_fields, 
            convert_to_tensor=True,
            show_progress_bar=True
        )
        print("âœ… í‘œì¤€ í•„ë“œ ì„ë² ë”© ìƒì„± ì™„ë£Œ")
    
    def predict_mapping(self, input_fields: List[str], threshold: float = 0.5) -> List[Dict]:
        """
        ì…ë ¥ í•„ë“œë“¤ì˜ ë§¤í•‘ ì˜ˆì¸¡
        
        Args:
            input_fields: ì…ë ¥ í•„ë“œ ë¦¬ìŠ¤íŠ¸
            threshold: ë§¤í•‘ ì‹ ë¢°ë„ ì„ê³„ê°’
            
        Returns:
            ë§¤í•‘ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if self.standard_embeddings is None:
            self.create_standard_embeddings()
        
        print(f"ğŸ”„ {len(input_fields)}ê°œ í•„ë“œ ë§¤í•‘ ì˜ˆì¸¡ ì¤‘...")
        
        # ì…ë ¥ í•„ë“œ ì„ë² ë”© ìƒì„±
        input_embeddings = self.model.encode(
            input_fields, 
            convert_to_tensor=True,
            show_progress_bar=True
        )
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = cosine_similarity(
            input_embeddings.cpu().numpy(), 
            self.standard_embeddings.cpu().numpy()
        )
        
        results = []
        for i, input_field in enumerate(input_fields):
            # ê°€ì¥ ìœ ì‚¬í•œ í‘œì¤€ í•„ë“œ ì°¾ê¸°
            max_sim_idx = np.argmax(similarities[i])
            max_similarity = similarities[i][max_sim_idx]
            
            result = {
                "input_field": input_field,
                "predicted_mapping": self.standard_fields[max_sim_idx] if max_similarity >= threshold else None,
                "confidence": float(max_similarity),
                "all_candidates": []
            }
            
            # ìƒìœ„ 5ê°œ í›„ë³´ë“¤ ì¶”ê°€
            top_indices = np.argsort(similarities[i])[-5:][::-1]
            for idx in top_indices:
                result["all_candidates"].append({
                    "standard_field": self.standard_fields[idx],
                    "similarity": float(similarities[i][idx])
                })
            
            results.append(result)
        
        print("âœ… ë§¤í•‘ ì˜ˆì¸¡ ì™„ë£Œ")
        return results
    
    def evaluate_mapping(self, test_data: List[Dict]) -> Dict:
        """
        ë§¤í•‘ ì„±ëŠ¥ í‰ê°€
        
        Args:
            test_data: í…ŒìŠ¤íŠ¸ ë°ì´í„° (ì •ë‹µ í¬í•¨)
            
        Returns:
            í‰ê°€ ê²°ê³¼
        """
        correct = 0
        total = len(test_data)
        
        for item in test_data:
            input_field = item.get('input_field')
            correct_mapping = item.get('correct_mapping')
            
            if input_field and correct_mapping:
                # ë‹¨ì¼ í•„ë“œ ì˜ˆì¸¡
                prediction = self.predict_mapping([input_field])[0]
                if prediction['predicted_mapping'] == correct_mapping:
                    correct += 1
        
        accuracy = correct / total if total > 0 else 0
        
        return {
            "accuracy": accuracy,
            "correct": correct,
            "total": total,
            "error_rate": 1 - accuracy
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
trainer = FieldMappingTrainer()
